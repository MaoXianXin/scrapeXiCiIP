2016-12-25 14:35:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:35:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:35:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:35:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:35:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:35:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:35:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:35:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:35:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:35:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:35:03 [scrapy] INFO: Spider opened
2016-12-25 14:35:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:35:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:35:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:35:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:35:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:35:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:35:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:35:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:35:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 14:35:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:35:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:35:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:35:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:35:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:35:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 14:35:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 14:35:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:35:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:35:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.105.54.63
2016-12-25 14:35:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 14:35:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:35:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 14:35:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 14:35:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:35:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:35:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:35:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:35:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 14:35:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:35:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:35:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:35:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 14:35:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:35:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:35:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 14:35:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:35:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:35:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 14:35:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:35:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:35:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:35:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:35:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:35:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:35:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:35:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:35:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:35:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:35:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 14:35:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:35:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.109.29.51
2016-12-25 14:36:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.206.45
2016-12-25 14:36:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:36:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:36:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:36:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:36:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:36:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:36:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:36:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:36:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:36:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:36:03 [scrapy] INFO: Spider opened
2016-12-25 14:36:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:36:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 14:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:36:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:36:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 8 items (at 8 items/min)
2016-12-25 14:36:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:36:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8456,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 36, 4, 523204),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 35, 3, 633778)}
2016-12-25 14:36:04 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 14:36:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:36:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:36:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:36:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 14:36:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:36:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:36:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:36:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:36:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 14:36:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:36:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:36:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 14:36:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:36:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 14:36:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 14:36:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:36:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:36:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:36:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:36:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 14:36:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:36:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:36:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 14:36:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 14:36:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:36:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:36:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:36:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:36:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 112.111.217.50
2016-12-25 14:36:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:36:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:36:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:36:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:36:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 14:36:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 14:36:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:36:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:36:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:36:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:36:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.109.29.51
2016-12-25 14:36:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.206.45
2016-12-25 14:37:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:37:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8454,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 37, 1, 216474),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 36, 3, 553703)}
2016-12-25 14:37:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
2016-12-25 14:37:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:37:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:37:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:37:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:37:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:37:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:37:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:37:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:37:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:37:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:37:03 [scrapy] INFO: Spider opened
2016-12-25 14:37:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:37:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:37:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:37:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:37:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:37:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 14:37:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:37:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:37:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:37:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:37:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:37:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:37:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:37:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:37:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:37:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:37:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:37:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 14:37:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:37:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 14:37:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:37:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.105.54.63
2016-12-25 14:37:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 14:37:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:37:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 14:37:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:37:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:37:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:37:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:37:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 14:37:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:37:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:37:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:37:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:37:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:37:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:37:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 112.111.217.50
2016-12-25 14:37:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 14:37:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:37:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:37:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:37:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:37:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:37:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.109.29.51
2016-12-25 14:37:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.206.45
2016-12-25 14:37:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:37:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8454,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 37, 55, 898136),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 37, 3, 570931)}
2016-12-25 14:37:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 14:38:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:38:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:38:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:38:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:38:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:38:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:38:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:38:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:38:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:38:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:38:03 [scrapy] INFO: Spider opened
2016-12-25 14:38:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:38:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:38:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:38:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:38:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:38:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.205
2016-12-25 14:38:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.89.6.224
2016-12-25 14:38:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:38:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 14:38:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:38:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:38:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:38:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:38:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:38:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:38:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:38:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:38:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:38:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:38:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:38:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:38:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 14:38:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 14:38:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:38:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:38:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:38:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:38:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:38:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:38:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 14:38:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 14:38:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:38:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 14:38:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:38:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:38:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 14:38:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 14:38:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:38:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 14:38:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:38:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 112.111.217.50
2016-12-25 14:38:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 14:38:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 14:38:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:38:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:38:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:38:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:38:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:38:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:38:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:39:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:39:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:39:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:39:01 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:39:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:39:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8493,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 39, 1, 635098),
 'item_scraped_count': 8,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 38, 3, 516324)}
2016-12-25 14:39:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
2016-12-25 14:39:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:39:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:39:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:39:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:39:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:39:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:39:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:39:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:39:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:39:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:39:03 [scrapy] INFO: Spider opened
2016-12-25 14:39:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:39:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:39:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:39:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:39:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:39:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 14:39:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.205
2016-12-25 14:39:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.89.6.224
2016-12-25 14:39:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:39:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:39:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 14:39:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:39:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 14:39:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:39:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:39:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:39:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:39:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:39:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:39:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:39:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:39:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:39:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:39:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:39:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:39:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:39:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:39:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:39:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:39:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:39:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 14:39:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:39:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:39:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:39:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 14:39:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:39:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:39:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:39:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:39:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:39:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:39:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:39:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:39:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:39:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:39:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:39:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:39:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:39:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:39:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:40:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:40:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8495,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 40, 1, 46565),
 'item_scraped_count': 4,
 'log_count/DEBUG': 21,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 39, 3, 557357)}
2016-12-25 14:40:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 14:40:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:40:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:40:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:40:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:40:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:40:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:40:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:40:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:40:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:40:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:40:03 [scrapy] INFO: Spider opened
2016-12-25 14:40:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:40:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:40:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.205
2016-12-25 14:40:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.89.6.224
2016-12-25 14:40:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:40:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 14:40:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 14:40:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:40:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:40:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:40:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:40:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:40:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:40:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:40:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:40:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:40:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:40:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:40:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:40:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 14:40:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:40:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:40:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:40:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:40:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:40:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:40:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 14:40:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:40:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:40:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:40:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 112.111.217.50
2016-12-25 14:40:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:40:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:40:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:40:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:40:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:40:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:40:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:40:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 14:40:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 14:40:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:40:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:40:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:40:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:40:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8494,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 40, 55, 939194),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 40, 3, 622524)}
2016-12-25 14:40:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
2016-12-25 14:41:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 14:41:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 14:41:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 14:41:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 14:41:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 14:41:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 14:41:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 14:41:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 14:41:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 14:41:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 14:41:03 [scrapy] INFO: Spider opened
2016-12-25 14:41:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 14:41:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 14:41:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 14:41:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 14:41:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 14:41:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 14:41:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 14:41:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 14:41:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.205
2016-12-25 14:41:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.89.6.224
2016-12-25 14:41:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 14:41:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 14:41:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 14:41:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 14:41:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 14:41:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 14:41:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 14:41:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 14:41:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 14:41:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:41:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 14:41:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 14:41:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 14:41:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.108.135
2016-12-25 14:41:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 14:41:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 14:41:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 14:41:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 14:41:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 14:41:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 14:41:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 14:41:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 14:41:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 14:41:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 112.111.217.50
2016-12-25 14:41:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:41:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 14:41:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 14:41:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 14:41:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 14:41:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 14:41:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 14:41:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 14:41:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8449,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 6, 41, 49, 707155),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 6, 41, 3, 562339)}
2016-12-25 14:41:49 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 15:13:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:13:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:13:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:13:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:13:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:13:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:13:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:13:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:13:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:13:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:13:03 [scrapy] INFO: Spider opened
2016-12-25 15:13:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:13:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:13:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:13:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:13:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:13:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:13:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:13:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:13:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:13:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:13:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:13:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:13:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:13:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:13:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:13:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:13:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:13:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:13:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 15:13:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:13:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 15:13:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:13:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:13:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:13:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:13:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:13:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:13:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:13:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:13:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:13:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:13:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 1.27.202.173
2016-12-25 15:13:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:13:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:13:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:13:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:13:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:13:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:13:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:13:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:13:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 15:13:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:13:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:13:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:13:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:13:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:13:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:13:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.48.224
2016-12-25 15:13:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:14:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:14:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:14:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:14:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:14:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:14:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:14:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:14:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:14:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:14:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:14:03 [scrapy] INFO: Spider opened
2016-12-25 15:14:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:14:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 15:14:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:14:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 15:14:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:14:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:14:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:14:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:14:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:14:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.118.96.197
2016-12-25 15:14:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 4 items (at 4 items/min)
2016-12-25 15:14:06 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:14:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8316,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 14, 6, 739166),
 'item_scraped_count': 4,
 'log_count/DEBUG': 21,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 13, 3, 679893)}
2016-12-25 15:14:06 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:14:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:14:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:14:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:14:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:14:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:14:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:14:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:14:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.218.117.80
2016-12-25 15:14:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:14:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:14:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:14:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:14:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:14:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:14:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:14:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:14:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:14:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:14:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:14:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:14:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:14:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:14:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:14:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:14:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 15:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:14:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:14:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:14:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 15:14:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:14:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.48.224
2016-12-25 15:14:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:14:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:14:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:14:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:14:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.146.246
2016-12-25 15:14:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:14:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8314,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 14, 48, 931778),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 14, 3, 609463)}
2016-12-25 15:14:48 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 15:15:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:15:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:15:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:15:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:15:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:15:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:15:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:15:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:15:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:15:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:15:03 [scrapy] INFO: Spider opened
2016-12-25 15:15:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:15:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:15:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:15:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:15:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:15:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 15:15:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:15:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:15:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:15:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:15:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:15:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:15:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:15:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:15:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:15:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:15:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:15:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:15:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:15:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:15:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:15:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 15:15:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:15:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:15:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:15:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:15:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:15:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:15:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:15:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 15:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:15:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:15:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:15:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:15:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 15:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:15:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:15:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:15:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:15:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 15:15:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.48.224
2016-12-25 15:15:50 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:15:50 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8387,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 15, 50, 202657),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 15, 3, 622102)}
2016-12-25 15:15:50 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:16:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:16:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:16:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:16:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:16:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:16:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:16:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:16:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:16:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:16:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:16:03 [scrapy] INFO: Spider opened
2016-12-25 15:16:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:16:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:16:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:16:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:16:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:16:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:16:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:16:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:16:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:16:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:16:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:16:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:16:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:16:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:16:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:16:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:16:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:16:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:16:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:16:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:16:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:16:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:16:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 15:16:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:16:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:16:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:16:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:16:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 15:16:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:16:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:16:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 202.104.230.29
2016-12-25 15:16:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:16:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:16:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:16:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:16:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:16:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:16:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:16:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 15:16:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:16:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:17:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.48.224
2016-12-25 15:17:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:17:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:17:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:17:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:17:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:17:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:17:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:17:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:17:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:17:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:17:03 [scrapy] INFO: Spider opened
2016-12-25 15:17:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:17:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 15:17:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:17:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:17:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:17:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 15:17:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:17:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8390,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 17, 4, 722665),
 'item_scraped_count': 7,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 16, 3, 642692)}
2016-12-25 15:17:04 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
403
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:17:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:17:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:17:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:17:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:17:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:17:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:17:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:17:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:17:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:17:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:17:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:17:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:17:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:17:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:17:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:17:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:17:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:17:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:17:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:17:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:17:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 15:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:17:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:17:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:17:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:17:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:17:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:17:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:17:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:17:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:17:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:17:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:17:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:17:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.48.224
2016-12-25 15:17:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:17:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 15:17:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:17:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:17:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8392,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 17, 55, 693284),
 'item_scraped_count': 7,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 17, 3, 646038)}
2016-12-25 15:17:55 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 15:18:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:18:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:18:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:18:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:18:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:18:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:18:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:18:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:18:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:18:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:18:03 [scrapy] INFO: Spider opened
2016-12-25 15:18:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:18:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:18:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:18:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:18:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:18:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:18:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:18:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 15:18:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:18:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:18:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:18:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:18:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:18:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:18:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:18:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:18:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:18:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:18:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:18:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:18:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:18:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:18:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:18:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:18:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:18:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:18:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:18:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:18:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:18:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:18:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:18:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:18:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:18:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:18:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 15:18:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:18:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:18:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:18:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 202.104.230.29
2016-12-25 15:18:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:18:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:18:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:18:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:18:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:18:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:18:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8318,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 18, 56, 934636),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 18, 3, 734242)}
2016-12-25 15:18:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
403
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:19:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:19:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:19:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:19:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:19:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:19:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:19:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:19:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:19:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:19:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:19:03 [scrapy] INFO: Spider opened
2016-12-25 15:19:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:19:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:19:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:19:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:19:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:19:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:19:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:19:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:19:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:19:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:19:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:19:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:19:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:19:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:19:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:19:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:19:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:19:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:19:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:19:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:19:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:19:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:19:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:19:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:19:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:19:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:19:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:19:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:19:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 15:19:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:19:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:19:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:19:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:19:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:19:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:19:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:19:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:19:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 15:19:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:19:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:19:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:19:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:19:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:19:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:19:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:19:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:19:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8321,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 19, 58, 570654),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 40,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 19, 3, 726946)}
2016-12-25 15:19:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:20:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:20:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:20:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:20:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:20:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:20:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:20:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:20:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:20:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:20:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:20:03 [scrapy] INFO: Spider opened
2016-12-25 15:20:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:20:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:20:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:20:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:20:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:20:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:20:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:20:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:20:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:20:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:20:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:20:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:20:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:20:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:20:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:20:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 15:20:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:20:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:20:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:20:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:20:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:20:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:20:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:20:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:20:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:20:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:20:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:20:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:20:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 15:20:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:20:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:20:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:20:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:20:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:20:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 202.104.230.29
2016-12-25 15:20:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:20:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:20:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:20:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:20:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:20:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 15:20:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:21:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:21:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:21:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:21:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:21:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:21:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:21:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.83.80
2016-12-25 15:21:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:21:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:21:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:21:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:21:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:21:03 [scrapy] INFO: Spider opened
2016-12-25 15:21:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:21:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 15:21:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:21:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:21:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:21:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 11 items (at 11 items/min)
2016-12-25 15:21:06 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:21:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8323,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 21, 6, 398180),
 'item_scraped_count': 11,
 'log_count/DEBUG': 40,
 'log_count/ERROR': 2,
 'log_count/INFO': 50,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 20, 3, 705894)}
2016-12-25 15:21:06 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:21:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:21:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:21:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:21:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:21:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 15:21:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:21:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:21:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:21:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:21:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:21:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:21:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:21:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:21:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:21:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:21:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:21:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:21:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:21:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:21:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:21:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:21:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:21:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:21:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:21:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:21:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:21:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:21:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:21:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:21:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:21:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 15:21:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:21:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:21:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:21:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 15:21:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:21:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:21:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:21:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8337,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 21, 58, 165596),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 21, 3, 696861)}
2016-12-25 15:21:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 15:24:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:24:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:24:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:24:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:24:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:24:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:24:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:24:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:24:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:24:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:24:03 [scrapy] INFO: Spider opened
2016-12-25 15:24:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:24:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:24:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:24:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:24:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:24:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:24:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 15:24:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:24:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:24:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:24:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:24:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:24:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:24:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:24:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:24:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:24:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:24:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:24:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:24:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:24:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:24:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:24:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:24:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:24:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:24:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:24:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 15:24:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:24:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:24:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 15:24:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 15:24:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:24:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:24:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 15:24:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:24:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:24:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:24:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:24:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:25:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:25:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:25:08 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 15:25:08 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:25:08 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8317,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 25, 8, 166441),
 'item_scraped_count': 9,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 24, 3, 754503)}
2016-12-25 15:25:08 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:28:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:28:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:28:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:28:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:28:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:28:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:28:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:28:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:28:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:28:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:28:03 [scrapy] INFO: Spider opened
2016-12-25 15:28:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:28:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:28:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:28:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:28:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:28:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:28:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 15:28:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:28:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:28:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:28:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:28:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:28:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:28:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:28:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:28:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:28:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:28:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:28:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:28:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:28:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:28:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:28:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:28:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:28:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:28:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:28:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:28:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:28:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:28:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:28:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:28:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 15:28:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:28:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:28:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:28:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 15:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 15:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:28:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:28:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.90.24
2016-12-25 15:28:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 15:28:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:28:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8328,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 28, 55, 31367),
 'item_scraped_count': 5,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 28, 3, 742931)}
2016-12-25 15:28:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
403
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:32:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:32:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:32:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:32:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:32:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:32:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:32:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:32:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:32:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:32:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:32:03 [scrapy] INFO: Spider opened
2016-12-25 15:32:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:32:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:32:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:32:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 15:32:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:32:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:32:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:32:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:32:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:32:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:32:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:32:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:32:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:32:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:32:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:32:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:32:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:32:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:32:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:32:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:32:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:32:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:32:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:32:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:32:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:32:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:32:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:32:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:32:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:32:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:32:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:32:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:32:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:32:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 15:32:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:32:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:32:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:32:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 15:32:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:32:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:32:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 1.27.202.173
2016-12-25 15:32:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 15:32:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:32:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8296,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 32, 52, 911543),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 32, 3, 746082)}
2016-12-25 15:32:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:36:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:36:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:36:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:36:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:36:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:36:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:36:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:36:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:36:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:36:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:36:03 [scrapy] INFO: Spider opened
2016-12-25 15:36:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:36:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:36:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:36:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:36:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:36:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:36:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:36:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:36:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:36:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:36:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:36:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:36:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 15:36:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:36:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:36:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:36:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:36:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:36:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:36:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:36:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:36:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 15:36:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:36:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:36:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:36:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:36:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:36:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:36:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:36:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:36:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:36:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 15:36:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 15:36:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:36:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8299,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 36, 49, 58805),
 'item_scraped_count': 5,
 'log_count/DEBUG': 22,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 36, 3, 763090)}
2016-12-25 15:36:49 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:40:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:40:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:40:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:40:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:40:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:40:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:40:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:40:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:40:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:40:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:40:03 [scrapy] INFO: Spider opened
2016-12-25 15:40:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:40:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:40:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:40:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 15:40:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.18.187.112
2016-12-25 15:40:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:40:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.176.46.17
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:40:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 15:40:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:40:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:40:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:40:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:40:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:40:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:40:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:40:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:40:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:40:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:40:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:40:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:40:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:40:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:40:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:40:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:40:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:40:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:40:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:40:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:40:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:40:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:40:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:40:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:40:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:40:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:40:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:40:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:40:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:40:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:40:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:40:46 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:40:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8309,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 40, 46, 704294),
 'item_scraped_count': 10,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 40, 3, 835097)}
2016-12-25 15:40:46 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:44:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:44:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:44:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:44:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:44:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:44:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:44:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:44:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:44:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:44:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:44:04 [scrapy] INFO: Spider opened
2016-12-25 15:44:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:44:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:44:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:44:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:44:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:44:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:44:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:44:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:44:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:44:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:44:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:44:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:44:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:44:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:44:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:44:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.18.187.112
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:44:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:44:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:44:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:44:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:44:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:44:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 15:44:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:44:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 15:44:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:44:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:44:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:44:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:44:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:44:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:44:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:44:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:44:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:44:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 15:44:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:44:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 15:44:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.31.250
2016-12-25 15:44:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 15:44:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:44:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 15:44:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:44:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8316,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 44, 52, 542552),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 44, 4, 255601)}
2016-12-25 15:44:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 15:48:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:48:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:48:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:48:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:48:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:48:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:48:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:48:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:48:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:48:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:48:03 [scrapy] INFO: Spider opened
2016-12-25 15:48:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:48:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:48:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 15:48:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 15:48:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 15:48:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 15:48:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 15:48:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 15:48:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:48:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 15:48:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 15:48:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:48:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 15:48:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:48:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:48:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:48:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:48:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:48:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:48:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:48:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:48:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 15:48:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:48:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:48:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:48:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 15:48:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 15:48:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.18.187.112
2016-12-25 15:48:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 15:48:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:48:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:48:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:48:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:48:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:48:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 15:48:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:48:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:48:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 15:48:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:48:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:48:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:48:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:48:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:48:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:48:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:48:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:48:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:48:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8241,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 48, 51, 283656),
 'item_scraped_count': 11,
 'log_count/DEBUG': 39,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 48, 3, 771002)}
2016-12-25 15:48:51 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 15:52:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:52:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:52:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:52:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:52:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:52:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:52:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:52:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:52:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:52:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:52:03 [scrapy] INFO: Spider opened
2016-12-25 15:52:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:52:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:52:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:52:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:52:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:52:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:52:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:52:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 15:52:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 15:52:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 15:52:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 15:52:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 15:52:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:52:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:52:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:52:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 15:52:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 15:52:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:52:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 15:52:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:52:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:52:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:52:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:52:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:52:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:52:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 15:52:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:52:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 15:52:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 15:52:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.176.225
2016-12-25 15:52:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 15:52:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:52:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:52:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:52:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:52:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:52:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:52:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 52, 56, 874319),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 52, 3, 806987)}
2016-12-25 15:52:56 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
2016-12-25 15:56:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 15:56:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 15:56:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 15:56:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 15:56:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 15:56:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 15:56:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 15:56:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 15:56:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 15:56:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 15:56:02 [scrapy] INFO: Spider opened
2016-12-25 15:56:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 15:56:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 15:56:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 15:56:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 15:56:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 15:56:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 15:56:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 15:56:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 15:56:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 15:56:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:56:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 15:56:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 15:56:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 15:56:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:56:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 15:56:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 15:56:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 15:56:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 15:56:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 15:56:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 15:56:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 15:56:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 15:56:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 15:56:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 15:56:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 15:56:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 15:56:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 15:56:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 15:56:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 15:56:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 15:56:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 15:56:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 15:56:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 15:56:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 15:56:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 15:56:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:56:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 15:56:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 15:56:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 15:56:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 15:56:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 15:56:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 15:56:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 15:56:46 [scrapy] INFO: Closing spider (finished)
2016-12-25 15:56:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8234,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 7, 56, 46, 58895),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 7, 56, 2, 828337)}
2016-12-25 15:56:46 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 16:00:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:00:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:00:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:00:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:00:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:00:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:00:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:00:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:00:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:00:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:00:02 [scrapy] INFO: Spider opened
2016-12-25 16:00:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:00:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:00:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:00:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:00:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.235.135.120
2016-12-25 16:00:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 16:00:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 16:00:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:00:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:00:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 16:00:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 16:00:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:00:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:00:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:00:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 16:00:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:00:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:00:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:00:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:00:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 16:00:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:00:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:00:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:00:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:00:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:00:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 16:00:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:00:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 16:00:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:00:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 16:00:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.58
2016-12-25 16:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:00:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.58
2016-12-25 16:00:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:00:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:00:44 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:00:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8249,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 0, 44, 646889),
 'item_scraped_count': 10,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 0, 2, 793356)}
2016-12-25 16:00:44 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 16:04:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:04:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:04:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:04:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:04:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:04:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:04:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:04:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:04:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:04:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:04:02 [scrapy] INFO: Spider opened
2016-12-25 16:04:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:04:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:04:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:04:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:04:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:04:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 16:04:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:04:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.64.12.154
2016-12-25 16:04:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:04:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:04:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:04:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:04:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:04:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:04:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:04:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:04:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:04:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:04:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:04:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:04:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:04:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:04:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:04:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 16:04:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:04:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:04:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:04:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.36.13
2016-12-25 16:04:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.235.135.120
2016-12-25 16:04:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 16:04:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 16:04:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 16:04:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 16:04:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 16:04:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 16:04:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:04:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:04:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 16:04:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:04:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 16:04:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 16:04:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 16:04:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 16:04:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:04:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:04:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:04:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:04:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:04:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:04:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:04:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 16:04:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:04:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:04:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:04:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8252,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 4, 56, 403543),
 'item_scraped_count': 9,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 4, 2, 837521)}
2016-12-25 16:04:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
2016-12-25 16:08:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:08:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:08:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:08:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:08:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:08:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:08:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:08:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:08:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:08:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:08:02 [scrapy] INFO: Spider opened
2016-12-25 16:08:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:08:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:08:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:08:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:08:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:08:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:08:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:08:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:08:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:08:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:08:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:08:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:08:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:08:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:08:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:08:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:08:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 16:08:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.118.96.197
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 16:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.36.13
2016-12-25 16:08:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.235.135.120
2016-12-25 16:08:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 16:08:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 16:08:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 16:08:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 16:08:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 16:08:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:08:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 16:08:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 16:08:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 16:08:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:08:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 16:08:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 16:08:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:08:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 16:08:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:08:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:08:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:08:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8292,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 8, 54, 477022),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 8, 2, 840769)}
2016-12-25 16:08:54 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:12:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:12:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:12:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:12:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:12:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:12:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:12:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:12:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:12:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:12:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:12:02 [scrapy] INFO: Spider opened
2016-12-25 16:12:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:12:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:12:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:12:08 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:12:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:12:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:12:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:12:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:12:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:12:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:12:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:12:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:12:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:12:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:12:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:12:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:12:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 16:12:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:12:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:12:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:12:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.36.13
2016-12-25 16:12:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.235.135.120
2016-12-25 16:12:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 16:12:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 16:12:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:12:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 16:12:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 16:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 16:12:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 16:12:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 16:12:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:12:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 16:12:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:12:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 16:12:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:12:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 16:12:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:12:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 16:12:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:12:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 16:12:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:12:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:12:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8289,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 12, 58, 893862),
 'item_scraped_count': 6,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 12, 2, 979567)}
2016-12-25 16:12:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:16:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:16:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:16:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:16:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:16:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:16:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:16:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:16:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:16:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:16:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:16:02 [scrapy] INFO: Spider opened
2016-12-25 16:16:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:16:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:16:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:16:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:16:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:16:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 16:16:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:16:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:16:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:16:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:16:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:16:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:16:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:16:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:16:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:16:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:16:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:16:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:16:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:16:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:16:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 16:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:16:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:16:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.38.220.187
2016-12-25 16:16:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:16:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:16:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:16:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:16:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.118.96.197
2016-12-25 16:16:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.36.13
2016-12-25 16:16:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.235.135.120
2016-12-25 16:16:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 16:16:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 16:16:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.88.231.179
2016-12-25 16:16:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 16:16:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:16:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8262,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 16, 52, 567821),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 16, 2, 918216)}
2016-12-25 16:16:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:20:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:20:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:20:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:20:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:20:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:20:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:20:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:20:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:20:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:20:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:20:02 [scrapy] INFO: Spider opened
2016-12-25 16:20:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:20:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:20:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:20:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 16:20:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:20:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.178.34.254
2016-12-25 16:20:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:20:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:20:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:20:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:20:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:20:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:20:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:20:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:20:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 16:20:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 403 0
2016-12-25 16:20:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 16:20:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:20:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:20:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.18.187.112
2016-12-25 16:20:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:20:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 16:20:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 16:20:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:20:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:20:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:20:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:20:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:20:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:20:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:20:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:20:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:20:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:20:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:20:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:20:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:20:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 16:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:20:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.64.12.154
2016-12-25 16:20:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:20:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:20:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:20:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:20:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8185,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 20, 52, 818049),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 20, 2, 953196)}
2016-12-25 16:20:52 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
403
200
connect failed!
200
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:24:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:24:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:24:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:24:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:24:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:24:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:24:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:24:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:24:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:24:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:24:02 [scrapy] INFO: Spider opened
2016-12-25 16:24:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:24:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:24:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:24:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:24:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:24:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:24:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:24:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:24:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:24:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:24:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:24:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:24:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:24:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:24:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:24:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:24:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:24:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:24:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:24:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:24:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:24:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:24:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:24:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 16:24:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:24:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:24:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:24:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:24:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:24:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:24:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 16:24:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:24:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:24:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 16:24:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:25:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.92.38
2016-12-25 16:25:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.101
2016-12-25 16:25:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 16:25:07 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:25:07 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8254,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 25, 7, 454887),
 'item_scraped_count': 7,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 24, 2, 999690)}
2016-12-25 16:25:07 [scrapy] INFO: Spider closed (finished)
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:28:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:28:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:28:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:28:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:28:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:28:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:28:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:28:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:28:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:28:02 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:28:02 [scrapy] INFO: Spider opened
2016-12-25 16:28:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:28:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:28:02 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:28:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:28:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:28:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:28:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:28:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:28:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:28:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:28:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:28:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:28:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 16:28:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:28:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:28:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:28:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:28:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:28:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:28:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:28:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:28:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:28:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:28:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:28:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:28:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:28:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:28:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:28:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:28:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 16:28:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:28:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:28:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 16:28:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:28:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 16:28:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 16:28:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:28:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 16:28:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:28:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:28:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:28:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8217,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 28, 56, 145698),
 'item_scraped_count': 10,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 28, 2, 910787)}
2016-12-25 16:28:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
200
2016-12-25 16:32:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:32:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:32:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:32:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:32:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:32:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:32:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:32:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:32:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:32:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:32:03 [scrapy] INFO: Spider opened
2016-12-25 16:32:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:32:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:32:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:32:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:32:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:32:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:32:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:32:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:32:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:32:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:32:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:32:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 16:32:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:32:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:32:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:32:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:32:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:32:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:32:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:32:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:32:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:32:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:32:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:32:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:32:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:32:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:32:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:32:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:32:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:32:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:32:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:32:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:32:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 16:32:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:32:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:32:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:32:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8284,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 32, 55, 785050),
 'item_scraped_count': 7,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 32, 3, 24635)}
2016-12-25 16:32:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
2016-12-25 16:36:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:36:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:36:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:36:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:36:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:36:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:36:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:36:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:36:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:36:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:36:03 [scrapy] INFO: Spider opened
2016-12-25 16:36:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:36:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:36:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:36:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:36:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 16:36:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 16:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:36:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:36:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:36:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:36:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:36:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:36:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:36:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:36:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:36:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 16:36:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:36:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 16:36:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:36:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:36:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:36:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:36:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:36:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:36:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:36:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:36:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:36:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:36:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:36:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:36:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:36:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:36:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:36:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:36:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:36:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:36:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:36:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 202.104.230.29
2016-12-25 16:36:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:36:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 16:36:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:36:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 16:37:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:37:00 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:37:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 16:37:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:37:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 16:37:03 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 8 items (at 8 items/min)
2016-12-25 16:37:03 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:37:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8315,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 37, 3, 712462),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 36, 3, 31199)}
2016-12-25 16:37:03 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 16:40:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:40:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:40:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:40:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:40:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:40:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:40:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:40:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:40:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:40:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:40:03 [scrapy] INFO: Spider opened
2016-12-25 16:40:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:40:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 16:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 16:40:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 16:40:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 16:40:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 16:40:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:40:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.178.34.254
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:40:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:40:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:40:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:40:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:40:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:40:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:40:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:40:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:40:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:40:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:40:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:40:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:40:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 16:40:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:40:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:40:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:40:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:40:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:40:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:40:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:40:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:40:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:40:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:40:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:40:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:40:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:40:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:40:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:40:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.35.5
2016-12-25 16:40:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.79.23
2016-12-25 16:40:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.85.178
2016-12-25 16:40:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:40:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8399,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 40, 59, 678243),
 'item_scraped_count': 10,
 'log_count/DEBUG': 35,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 40, 3, 84124)}
2016-12-25 16:40:59 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:44:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:44:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:44:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:44:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:44:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:44:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:44:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:44:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:44:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:44:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:44:03 [scrapy] INFO: Spider opened
2016-12-25 16:44:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:44:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:44:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 16:44:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 16:44:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:44:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:44:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:44:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 16:44:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:44:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:44:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:44:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 16:44:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:44:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 16:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 16:44:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 16:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 16:44:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 16:44:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 16:44:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 16:44:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:44:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:44:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:44:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:44:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:44:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:44:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:44:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 16:44:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 16:44:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:44:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:44:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:44:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:44:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:44:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:44:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:44:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:44:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:44:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:44:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 16:44:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:44:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.6.220
2016-12-25 16:44:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.215.36
2016-12-25 16:44:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.173.235
2016-12-25 16:45:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:45:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8362,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 45, 1, 557119),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 44, 3, 91040)}
2016-12-25 16:45:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 16:48:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:48:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:48:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:48:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:48:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:48:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:48:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:48:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:48:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:48:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:48:03 [scrapy] INFO: Spider opened
2016-12-25 16:48:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:48:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:48:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 16:48:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 16:48:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 16:48:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:48:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:48:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 16:48:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:48:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:48:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:48:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:48:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:48:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:48:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:48:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:48:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:48:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.178.34.254
2016-12-25 16:48:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 16:48:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 16:48:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 16:48:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 16:48:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 16:48:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 16:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 16:48:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:48:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:48:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:48:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:48:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:48:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:48:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:48:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 16:48:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:48:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:48:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:48:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:48:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:48:59 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:48:59 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:48:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:49:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:49:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8354,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 49, 0, 11929),
 'item_scraped_count': 9,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 48, 3, 13677)}
2016-12-25 16:49:00 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
2016-12-25 16:52:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:52:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:52:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:52:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:52:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:52:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:52:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:52:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:52:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:52:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:52:03 [scrapy] INFO: Spider opened
2016-12-25 16:52:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:52:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:52:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 16:52:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 16:52:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 175.30.158.134
2016-12-25 16:52:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 16:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:52:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:52:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:52:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:52:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:52:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:52:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:52:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 16:52:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:52:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.178.34.254
2016-12-25 16:52:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 16:52:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 16:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 16:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 16:52:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 16:52:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:52:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:52:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 16:52:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:52:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:52:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:52:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 16:52:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 16:52:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:52:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:52:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 16:52:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:52:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 16:52:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:52:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:52:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 16:52:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.176
2016-12-25 16:52:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:52:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.176
2016-12-25 16:52:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:52:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:52:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 16:53:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.18.187.112
2016-12-25 16:53:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:53:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8355,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 53, 1, 990652),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 52, 3, 77069)}
2016-12-25 16:53:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 16:56:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 16:56:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 16:56:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 16:56:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 16:56:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 16:56:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 16:56:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 16:56:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 16:56:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 16:56:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 16:56:03 [scrapy] INFO: Spider opened
2016-12-25 16:56:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 16:56:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 16:56:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 16:56:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 16:56:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 16:56:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 16:56:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:56:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 16:56:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 16:56:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 16:56:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 16:56:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 16:56:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 16:56:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 16:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 16:56:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 16:56:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 16:56:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 16:56:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 16:56:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 16:56:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:56:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 16:56:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 16:56:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 16:56:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 16:56:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 16:56:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 16:56:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 16:56:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 16:56:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 16:56:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.209.241.201
2016-12-25 16:56:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:56:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 16:56:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 16:56:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:56:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 16:56:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 16:56:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 16:56:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:56:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 16:56:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:56:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 16:56:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 16:57:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:57:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 16:57:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:57:01 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:57:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 16:57:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 16:57:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 16:57:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 16:57:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:57:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 16:57:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:57:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:57:03 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 16:57:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 16:57:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 16:57:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 16:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 16:57:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 16:57:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.50.106
2016-12-25 16:57:09 [scrapy] INFO: Closing spider (finished)
2016-12-25 16:57:09 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8243,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 8, 57, 9, 174891),
 'item_scraped_count': 10,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 8, 56, 3, 124164)}
2016-12-25 16:57:09 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
200
403
connect failed!
200
200
connect failed!
2016-12-25 17:00:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:00:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:00:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:00:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:00:01 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:00:02 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:00:02 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:00:02 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:00:02 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:00:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:00:03 [scrapy] INFO: Spider opened
2016-12-25 17:00:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:00:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:00:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:00:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:00:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:00:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.105.54.63
2016-12-25 17:00:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:00:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:00:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:00:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:00:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:00:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:00:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:00:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:00:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:00:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:00:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:00:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:00:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:00:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 14.114.11.107
2016-12-25 17:00:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:00:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:00:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:00:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:00:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:00:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:00:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:00:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:00:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:00:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:00:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:00:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:00:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 17:00:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:01:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:01:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:01:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:01:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 17:01:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 17:01:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:01:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 17:01:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 17:01:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:01:09 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:01:09 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8254,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 1, 9, 307128),
 'item_scraped_count': 7,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 0, 3, 3626)}
2016-12-25 17:01:09 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
403
connect failed!
200
200
2016-12-25 17:04:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:04:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:04:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:04:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:04:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:04:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:04:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:04:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:04:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:04:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:04:03 [scrapy] INFO: Spider opened
2016-12-25 17:04:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:04:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:04:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:04:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:04:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:04:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:04:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:04:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:04:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:04:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 17:04:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:04:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:04:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:04:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:04:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.105.54.63
2016-12-25 17:04:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:04:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:04:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.38.220.187
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:04:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:04:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:04:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:04:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:04:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:04:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:04:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 175.30.158.134
2016-12-25 17:04:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:04:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:04:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:04:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:04:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:04:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.209.241.201
2016-12-25 17:04:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:04:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:04:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 17:04:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:05:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:05:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:05:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 17:05:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:05:05 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:05:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 17:05:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:05:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:05:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 17:05:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:05:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 17:05:10 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:05:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8296,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 5, 10, 318049),
 'item_scraped_count': 6,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 4, 3, 93488)}
2016-12-25 17:05:10 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
403
200
200
connect failed!
2016-12-25 17:08:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:08:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:08:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:08:01 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:08:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:08:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:08:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:08:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:08:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:08:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:08:03 [scrapy] INFO: Spider opened
2016-12-25 17:08:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:08:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 17:08:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:08:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:08:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:08:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 17:08:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:08:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:08:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:08:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:08:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:08:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:08:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:08:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 17:08:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:08:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:08:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:08:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:08:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:08:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:08:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:08:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:08:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:08:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:08:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:08:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:08:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:08:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:08:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:08:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:08:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:08:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:08:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:08:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:08:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:08:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:08:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:08:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:08:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.209.241.201
2016-12-25 17:09:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:09:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:09:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 17:09:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:09:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:09:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:09:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 17:09:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:09:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:09:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 17:09:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 17:09:13 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 17:09:13 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:09:13 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8271,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 9, 13, 661552),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 8, 3, 59070)}
2016-12-25 17:09:13 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
403
2016-12-25 17:12:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:12:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:12:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:12:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:12:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:12:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:12:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:12:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:12:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:12:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:12:03 [scrapy] INFO: Spider opened
2016-12-25 17:12:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:12:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:12:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:12:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 17:12:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:12:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:12:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:12:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:12:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:12:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:12:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:12:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:12:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:12:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:12:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 17:12:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:12:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:12:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 17:12:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:12:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:12:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:12:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:12:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:12:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 17:12:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:12:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:12:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:12:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:12:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:12:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:12:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:12:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:12:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:12:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 17:12:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:12:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:12:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:12:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:12:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.209.241.201
2016-12-25 17:12:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:12:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.92.150.210
2016-12-25 17:13:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:13:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:13:03 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 17:13:03 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:13:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8276,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 13, 3, 962642),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 12, 3, 88095)}
2016-12-25 17:13:03 [scrapy] INFO: Spider closed (finished)
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
500
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 17:16:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:16:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:16:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:16:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:16:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:16:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:16:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:16:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:16:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:16:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:16:03 [scrapy] INFO: Spider opened
2016-12-25 17:16:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:16:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 17:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:16:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:16:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 17:16:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:16:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:16:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 17:16:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 17:16:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:16:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:16:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:16:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:16:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:16:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:16:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:16:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:16:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:16:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:16:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:16:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:16:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:16:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:16:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:16:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:16:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:16:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 17:16:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:16:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:16:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:16:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:16:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:16:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:16:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:16:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.209.241.201
2016-12-25 17:16:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:17:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:17:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8313,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 17, 2, 362792),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 16, 3, 95067)}
2016-12-25 17:17:02 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 17:20:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:20:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:20:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:20:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:20:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:20:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:20:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:20:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:20:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:20:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:20:03 [scrapy] INFO: Spider opened
2016-12-25 17:20:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:20:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:20:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.64.12.154
2016-12-25 17:20:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 17:20:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:20:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:20:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:20:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:20:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:20:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:20:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:20:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:20:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:20:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 17:20:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:20:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:20:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:20:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:20:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:20:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 17:20:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:20:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:20:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:20:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:20:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:20:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:20:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:20:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:20:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:20:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:20:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:20:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:20:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:20:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.1.225
2016-12-25 17:21:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:21:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8313,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 21, 1, 843934),
 'item_scraped_count': 7,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 20, 3, 135328)}
2016-12-25 17:21:01 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
200
500
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 17:24:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:24:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:24:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:24:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:24:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:24:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:24:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:24:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:24:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:24:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:24:03 [scrapy] INFO: Spider opened
2016-12-25 17:24:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:24:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:24:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 17:24:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:24:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:24:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:24:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:24:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:24:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:24:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:24:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:24:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:24:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:24:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:24:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:24:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:24:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:24:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 17:24:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:24:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:24:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 17:24:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:24:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 17:24:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:24:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 17:24:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:24:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:24:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:24:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:24:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:24:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 17:24:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:24:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:24:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:24:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:24:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 14.114.11.107
2016-12-25 17:24:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:24:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:24:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:24:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:24:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 175.30.158.134
2016-12-25 17:24:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:25:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 17:25:05 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 17:25:05 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:25:05 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8323,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 25, 5, 478882),
 'item_scraped_count': 9,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 24, 3, 89821)}
2016-12-25 17:25:05 [scrapy] INFO: Spider closed (finished)
200
500
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
2016-12-25 17:28:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:28:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:28:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:28:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:28:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:28:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:28:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:28:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:28:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:28:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:28:03 [scrapy] INFO: Spider opened
2016-12-25 17:28:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:28:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:28:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 17:28:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:28:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 17:28:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:28:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:28:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:28:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:28:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:28:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:28:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:28:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:28:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:28:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 17:28:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:28:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 17:28:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:28:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:28:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:28:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:28:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:28:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:28:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:28:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:28:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:28:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:28:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:28:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:28:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 17:28:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:28:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:28:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 17:28:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:28:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:28:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:28:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:28:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 17:28:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:28:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:28:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.91.146.77
2016-12-25 17:28:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:28:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 17:28:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:28:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:28:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:28:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:28:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 175.30.158.134
2016-12-25 17:28:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:28:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:28:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:28:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:28:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8329,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 28, 57, 108895),
 'item_scraped_count': 11,
 'log_count/DEBUG': 41,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 28, 3, 125695)}
2016-12-25 17:28:57 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 17:32:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:32:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:32:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:32:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:32:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:32:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:32:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:32:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:32:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:32:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:32:03 [scrapy] INFO: Spider opened
2016-12-25 17:32:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:32:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:32:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:32:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:32:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 17:32:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:32:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 17:32:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:32:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:32:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 17:32:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:32:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:32:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:32:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:32:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:32:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:32:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 17:32:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:32:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 17:32:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:32:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:32:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:32:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:32:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:32:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 17:32:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:32:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:32:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:32:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:32:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:32:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 17:32:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:32:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:32:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:32:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:32:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:32:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:32:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:32:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:32:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:32:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 17:32:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:32:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:32:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:32:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:32:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:32:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:32:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8345,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 32, 53, 234534),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 32, 3, 144384)}
2016-12-25 17:32:53 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 17:36:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:36:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:36:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:36:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:36:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:36:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:36:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:36:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:36:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:36:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:36:03 [scrapy] INFO: Spider opened
2016-12-25 17:36:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:36:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 17:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:36:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:36:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:36:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:36:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:36:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:36:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:36:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:36:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 17:36:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:36:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:36:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:36:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:36:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:36:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:36:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:36:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 17:36:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:36:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:36:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 17:36:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:36:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:36:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:36:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:36:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.64.12.154
2016-12-25 17:36:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:36:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:36:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:36:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:36:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:36:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:36:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:36:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:36:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.38.220.187
2016-12-25 17:36:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.91.146.77
2016-12-25 17:36:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 17:36:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 17:36:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:36:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 14.114.11.107
2016-12-25 17:36:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 17:36:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:36:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 175.30.158.134
2016-12-25 17:36:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.178.34.254
2016-12-25 17:36:46 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:36:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8294,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 36, 46, 559956),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 36, 3, 164035)}
2016-12-25 17:36:46 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 17:40:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:40:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:40:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:40:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:40:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:40:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:40:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:40:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:40:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:40:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:40:03 [scrapy] INFO: Spider opened
2016-12-25 17:40:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:40:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 17:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:40:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 17:40:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 17:40:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 17:40:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.176.46.17
2016-12-25 17:40:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 17:40:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 17:40:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:40:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:40:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 17:40:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:40:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 17:40:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:40:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:40:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:40:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:40:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:40:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:40:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:40:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:40:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:40:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:40:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:40:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:40:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 17:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:40:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:40:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:40:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:40:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.64.12.154
2016-12-25 17:40:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:40:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:40:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:40:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 17:40:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:40:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:40:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:40:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8255,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 40, 55, 805354),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 40, 3, 137023)}
2016-12-25 17:40:55 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
2016-12-25 17:44:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 17:44:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 17:44:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 17:44:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 17:44:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 17:44:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 17:44:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 17:44:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 17:44:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 17:44:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 17:44:03 [scrapy] INFO: Spider opened
2016-12-25 17:44:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 17:44:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 17:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 17:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 17:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 17:44:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 17:44:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:44:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 17:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 17:44:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 17:44:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 17:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 17:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 17:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 17:44:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 17:44:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 17:44:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 17:44:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 17:44:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 17:44:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 17:44:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:44:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 17:44:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 17:44:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 17:44:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 17:44:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 17:44:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 17:44:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 17:44:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:44:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 17:44:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 17:44:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 17:44:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:44:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 17:44:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 17:44:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 17:44:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 17:44:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.152.227
2016-12-25 17:44:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 17:44:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 17:44:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.64.12.154
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.73
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.73
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 17:44:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 17:44:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 17:44:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.105.54.63
2016-12-25 17:44:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 17:44:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 17:44:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8210,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 9, 44, 55, 61736),
 'item_scraped_count': 5,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 9, 44, 3, 139199)}
2016-12-25 17:44:55 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 19:42:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:42:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:42:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:42:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:42:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:42:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:42:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:42:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:42:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:42:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:42:03 [scrapy] INFO: Spider opened
2016-12-25 19:42:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:42:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 19:42:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:42:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:42:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:42:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:42:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:42:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:42:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:42:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:42:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:42:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:42:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:42:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:42:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:42:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 19:42:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:42:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:42:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 19:42:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:42:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:42:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.176.46.17
2016-12-25 19:42:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 19:42:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:42:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:42:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:42:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 19:42:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:42:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:42:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 19:42:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:42:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 19:42:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:42:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:42:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:42:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:42:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:42:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:42:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:42:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:42:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:42:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.242.136.125
2016-12-25 19:42:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.68
2016-12-25 19:42:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 19:42:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 19:43:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:43:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 19:43:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:43:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:43:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 19:43:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 19:43:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:43:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:43:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 19:43:14 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 19:43:14 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:43:14 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8370,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 43, 14, 389348),
 'item_scraped_count': 6,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 42, 3, 778585)}
2016-12-25 19:43:14 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
500
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 19:44:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:44:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:44:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:44:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:44:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:44:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:44:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:44:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:44:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:44:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:44:03 [scrapy] INFO: Spider opened
2016-12-25 19:44:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:44:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:44:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:44:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:44:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:44:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 19:44:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:44:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:44:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:44:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:44:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:44:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 19:44:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:44:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:44:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:44:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:44:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:44:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:44:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:44:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:44:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:44:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:44:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:44:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:44:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:44:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.242.136.125
2016-12-25 19:44:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.68
2016-12-25 19:44:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 19:44:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 19:44:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:44:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 112.111.217.50
2016-12-25 19:44:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:44:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 19:44:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:44:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:44:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 19:44:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:44:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8368,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 44, 52, 930123),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 44, 3, 631819)}
2016-12-25 19:44:52 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
500
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 19:46:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:46:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:46:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:46:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:46:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:46:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:46:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:46:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:46:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:46:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:46:03 [scrapy] INFO: Spider opened
2016-12-25 19:46:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:46:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:46:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:46:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:46:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:46:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:46:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 19:46:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 19:46:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:46:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:46:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:46:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:46:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:46:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 19:46:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:46:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:46:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:46:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:46:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:46:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:46:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:46:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 19:46:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:46:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 19:46:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:46:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 19:46:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:46:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:46:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:46:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 19:46:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:46:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:46:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:46:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.242.136.125
2016-12-25 19:46:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.68
2016-12-25 19:46:46 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:46:46 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8317,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 46, 46, 709356),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 46, 3, 588881)}
2016-12-25 19:46:46 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
500
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 19:48:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:48:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:48:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:48:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:48:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:48:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:48:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:48:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:48:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:48:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:48:03 [scrapy] INFO: Spider opened
2016-12-25 19:48:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:48:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:48:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:48:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:48:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:48:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:48:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:48:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:48:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:48:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:48:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:48:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:48:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:48:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 19:48:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:48:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:48:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 19:48:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:48:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:48:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:48:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:48:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 19:48:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:48:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:48:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:48:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:48:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:48:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:48:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:48:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 19:48:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:48:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:48:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:48:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:48:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:48:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:48:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:48:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 19:48:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:48:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:48:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:48:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 19:48:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:48:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:48:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8299,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 48, 48, 922848),
 'item_scraped_count': 10,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 48, 3, 580153)}
2016-12-25 19:48:48 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
503
connect failed!
2016-12-25 19:50:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:50:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:50:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:50:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:50:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:50:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:50:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:50:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:50:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:50:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:50:03 [scrapy] INFO: Spider opened
2016-12-25 19:50:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:50:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:50:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:50:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:50:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:50:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:50:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:50:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:50:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:50:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:50:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:50:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:50:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:50:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:50:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 19:50:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:50:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 19:50:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:50:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:50:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 19:50:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:50:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:50:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:50:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:50:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:50:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 19:50:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:50:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:50:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 19:50:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:50:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 19:50:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:50:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:50:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:50:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:50:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:50:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:50:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:50:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:50:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:50:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:50:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:50:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:50:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:50:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:50:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 19:50:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:50:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:50:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8301,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 50, 59, 775072),
 'item_scraped_count': 10,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 50, 3, 675103)}
2016-12-25 19:50:59 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 19:52:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:52:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:52:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:52:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:52:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:52:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:52:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:52:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:52:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:52:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:52:03 [scrapy] INFO: Spider opened
2016-12-25 19:52:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:52:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:52:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:52:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:52:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:52:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:52:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:52:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:52:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:52:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 19:52:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:52:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:52:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:52:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:52:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:52:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 19:52:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:52:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:52:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 19:52:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:52:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:52:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:52:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:52:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:52:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:52:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:52:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 19:52:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:52:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:52:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:52:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:52:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:52:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 19:52:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:52:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 19:52:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:52:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:52:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:52:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:52:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:52:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:52:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:52:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:52:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:52:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8326,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 52, 52, 988922),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 52, 3, 727699)}
2016-12-25 19:52:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
500
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 19:54:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:54:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:54:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:54:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:54:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:54:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:54:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:54:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:54:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:54:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:54:03 [scrapy] INFO: Spider opened
2016-12-25 19:54:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:54:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:54:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:54:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:54:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:54:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 19:54:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:54:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:54:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:54:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:54:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:54:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:54:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:54:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:54:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:54:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:54:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 19:54:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:54:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:54:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:54:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:54:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:54:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:54:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:54:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:54:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:54:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 19:54:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 19:54:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:54:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 19:54:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:54:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 19:54:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:54:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.185.124
2016-12-25 19:54:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 19:54:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.38.3
2016-12-25 19:54:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:54:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8328,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 54, 52, 53148),
 'item_scraped_count': 7,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 54, 3, 641902)}
2016-12-25 19:54:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 19:56:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:56:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:56:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:56:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:56:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:56:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:56:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:56:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:56:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:56:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:56:03 [scrapy] INFO: Spider opened
2016-12-25 19:56:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:56:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 19:56:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:56:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:56:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 19:56:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 19:56:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 19:56:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:56:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 19:56:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 19:56:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 19:56:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 19:56:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:56:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:56:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:56:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:56:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:56:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:56:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:56:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 19:56:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:56:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:56:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:56:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:56:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:56:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:56:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 19:56:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:56:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:56:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:56:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 19:56:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:56:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:56:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:56:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:56:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:56:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:56:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 19:56:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:56:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:56:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 19:57:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:57:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8303,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 57, 0, 6099),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 56, 3, 643212)}
2016-12-25 19:57:00 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 19:58:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 19:58:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 19:58:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 19:58:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 19:58:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 19:58:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 19:58:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 19:58:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 19:58:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 19:58:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 19:58:03 [scrapy] INFO: Spider opened
2016-12-25 19:58:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 19:58:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 19:58:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 19:58:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 19:58:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 19:58:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 19:58:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 19:58:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 19:58:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 19:58:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 19:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 19:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 19:58:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:58:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 19:58:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 19:58:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 19:58:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 19:58:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 19:58:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 19:58:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 19:58:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 19:58:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 19:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 19:58:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 19:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 19:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:58:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 19:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 19:58:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 19:58:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 19:58:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 19:58:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 19:58:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 19:58:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 19:58:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 19:58:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 19:58:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 19:58:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 19:58:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 19:58:42 [scrapy] INFO: Closing spider (finished)
2016-12-25 19:58:42 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8281,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 11, 58, 42, 840248),
 'item_scraped_count': 10,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 11, 58, 3, 740415)}
2016-12-25 19:58:42 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:00:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:00:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:00:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:00:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:00:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:00:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:00:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:00:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:00:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:00:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:00:03 [scrapy] INFO: Spider opened
2016-12-25 20:00:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:00:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:00:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:00:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:00:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:00:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:00:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:00:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:00:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:00:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:00:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:00:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:00:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:00:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:00:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:00:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:00:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:00:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:00:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:00:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:00:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:00:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:00:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:00:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:00:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:00:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:00:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:00:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:00:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:00:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:00:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:00:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:00:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:00:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:00:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:00:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:00:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:00:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:00:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:00:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:01:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:01:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8280,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 1, 2, 337475),
 'item_scraped_count': 4,
 'log_count/DEBUG': 21,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 0, 3, 864789)}
2016-12-25 20:01:02 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
2016-12-25 20:01:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:01:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:01:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:01:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:01:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:01:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:01:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:01:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:01:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:01:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:01:03 [scrapy] INFO: Spider opened
2016-12-25 20:01:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:01:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:01:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:01:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:01:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:01:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:01:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:01:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:01:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:01:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:01:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:01:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:01:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:01:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:01:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:01:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:01:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:01:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:01:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:01:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:01:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:01:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:01:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:01:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:01:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:01:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:01:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:01:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:01:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:01:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:01:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:01:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:01:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:01:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:01:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:01:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:01:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:01:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8283,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 1, 55, 979540),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 1, 3, 768617)}
2016-12-25 20:01:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:02:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:02:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:02:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:02:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:02:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:02:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:02:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:02:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:02:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:02:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:02:03 [scrapy] INFO: Spider opened
2016-12-25 20:02:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:02:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:02:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:02:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:02:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:02:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:02:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:02:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:02:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:02:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:02:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:02:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:02:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:02:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:02:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:02:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:02:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:02:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:02:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:02:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:02:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:02:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:02:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:02:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:02:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:02:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:02:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:02:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:02:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:02:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:02:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:02:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:02:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:02:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:02:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:02:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:02:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:02:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8278,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 2, 49, 322453),
 'item_scraped_count': 11,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 2, 3, 865608)}
2016-12-25 20:02:49 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:03:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:03:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:03:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:03:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:03:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:03:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:03:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:03:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:03:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:03:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:03:03 [scrapy] INFO: Spider opened
2016-12-25 20:03:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:03:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:03:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:03:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:03:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:03:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:03:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:03:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:03:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:03:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:03:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:11 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:03:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:03:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:03:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:03:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:03:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:03:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:03:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:03:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:03:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:03:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:03:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:03:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:03:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:03:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:03:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:03:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:03:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:03:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:03:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:03:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:03:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:03:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:03:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:03:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:03:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:03:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:03:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:03:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:03:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:03:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:04:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:04:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:04:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:04:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:04:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:04:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:04:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:04:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:04:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:04:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:04:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:04:03 [scrapy] INFO: Spider opened
2016-12-25 20:04:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:04:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:04:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 20:04:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:04:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8278,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 4, 4, 533948),
 'item_scraped_count': 9,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 3, 3, 844426)}
2016-12-25 20:04:04 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:04:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:04:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:04:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:04:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:04:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:04:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:04:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:04:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:04:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:04:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:04:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:04:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:04:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:04:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:04:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 20:04:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:04:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:04:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:04:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:04:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:04:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:04:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:04:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:04:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:04:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:04:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:04:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:04:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:04:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:04:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:04:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:04:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:04:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:04:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:04:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:04:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:04:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:04:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:04:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8358,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 4, 49, 280543),
 'item_scraped_count': 11,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 4, 3, 855431)}
2016-12-25 20:04:49 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:05:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:05:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:05:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:05:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:05:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:05:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:05:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:05:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:05:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:05:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:05:04 [scrapy] INFO: Spider opened
2016-12-25 20:05:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:05:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:05:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:05:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:05:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:05:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:05:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:05:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:05:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:05:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:05:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:05:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:05:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:05:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:05:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:05:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:05:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:05:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:05:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:05:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:05:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:05:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:05:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:05:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:05:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:05:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:05:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:05:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:05:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:05:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:05:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:05:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1284
2016-12-25 20:05:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:05:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:05:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:05:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:05:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:05:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:05:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:05:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:05:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:05:41 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:05:41 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8358,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 5, 41, 872761),
 'item_scraped_count': 8,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 5, 4, 280473)}
2016-12-25 20:05:41 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:06:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:06:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:06:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:06:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:06:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:06:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:06:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:06:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:06:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:06:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:06:04 [scrapy] INFO: Spider opened
2016-12-25 20:06:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:06:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:06:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:06:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:06:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:06:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:06:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:06:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:06:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:06:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:06:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:06:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:06:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:06:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:06:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:06:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:06:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:06:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:06:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:06:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:06:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:06:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:06:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:06:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:06:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:06:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 20:06:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:06:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:06:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:06:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:06:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:06:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:06:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:06:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:06:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:06:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:06:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 223.244.50.186
2016-12-25 20:06:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:06:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:06:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:06:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:06:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.176.46.17
2016-12-25 20:06:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.37.170.157
2016-12-25 20:06:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:06:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8357,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 6, 58, 25931),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 6, 4, 664994)}
2016-12-25 20:06:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:07:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:07:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:07:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:07:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:07:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:07:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:07:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:07:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:07:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:07:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:07:04 [scrapy] INFO: Spider opened
2016-12-25 20:07:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:07:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:07:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:07:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:07:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:07:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:07:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:07:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:07:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:07:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:07:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:07:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:07:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:07:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:07:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:07:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:07:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:07:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:07:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:07:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:07:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:07:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:07:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:07:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:07:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:07:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:07:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:07:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:07:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:07:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:07:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:07:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:07:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:07:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:07:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:07:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:07:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:07:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:07:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:07:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:07:57 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:07:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:07:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:07:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8394,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 7, 57, 373769),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 7, 4, 771072)}
2016-12-25 20:07:57 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:08:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:08:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:08:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:08:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:08:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:08:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:08:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:08:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:08:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:08:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:08:04 [scrapy] INFO: Spider opened
2016-12-25 20:08:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:08:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:08:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:08:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:08:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:08:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:08:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:08:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:08:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:08:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:08:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:08:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:08:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:08:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:08:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:08:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:08:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:08:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:08:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:08:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:08:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:08:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:08:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:08:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:08:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:08:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:08:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:08:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:08:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:08:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:08:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:08:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:08:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:08:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:08:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:08:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:08:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:08:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:08:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:08:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:08:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:08:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:08:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8394,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 8, 51, 368340),
 'item_scraped_count': 11,
 'log_count/DEBUG': 40,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 8, 4, 146088)}
2016-12-25 20:08:51 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:09:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:09:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:09:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:09:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:09:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:09:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:09:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:09:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:09:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:09:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:09:04 [scrapy] INFO: Spider opened
2016-12-25 20:09:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:09:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:09:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:09:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:09:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:09:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:09:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:09:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:09:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:09:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:09:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:09:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:09:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:09:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:09:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:09:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:09:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:09:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:09:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:09:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:09:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:09:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:09:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:09:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:09:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:09:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:09:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:09:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:09:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:09:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 20:09:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:09:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:09:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:09:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:09:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:09:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:09:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:09:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:09:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:09:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:09:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:09:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:09:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:09:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:09:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:09:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:09:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:09:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:09:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:09:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8398,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 9, 58, 125926),
 'item_scraped_count': 8,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 9, 4, 265805)}
2016-12-25 20:09:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:10:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:10:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:10:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:10:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:10:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:10:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:10:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:10:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:10:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:10:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:10:04 [scrapy] INFO: Spider opened
2016-12-25 20:10:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:10:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:10:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:10:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:10:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:10:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:10:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:10:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 20:10:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:10:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:10:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:10:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:10:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:10:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:10:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:10:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:10:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:10:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:10:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:10:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:10:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:10:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:10:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:10:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:10:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:10:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:10:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:10:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:10:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:10:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:10:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:10:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:10:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:10:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:10:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:10:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 20:10:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:10:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:10:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:10:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:10:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:10:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:10:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:10:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:10:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:10:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:10:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:10:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:10:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:10:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:10:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:10:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:10:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:10:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:10:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8377,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 10, 58, 676265),
 'item_scraped_count': 10,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 51,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 10, 4, 85694)}
2016-12-25 20:10:58 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
2016-12-25 20:11:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:11:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:11:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:11:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:11:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:11:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:11:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:11:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:11:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:11:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:11:04 [scrapy] INFO: Spider opened
2016-12-25 20:11:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:11:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:11:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:11:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:11:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:11:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:11:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:11:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:11:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 20:11:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:11:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:11:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 20:11:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 17528
2016-12-25 20:11:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:11:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:11:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:11:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:11:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:11:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:11:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:11:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:11:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:11:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:11:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:11:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:11:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:11:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:11:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:11:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:11:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:11:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:11:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:11:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:11:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:11:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:11:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:11:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:11:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:11:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:11:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:11:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:11:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:11:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:11:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:11:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:11:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:11:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:11:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:11:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:11:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:11:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:11:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:11:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:12:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:12:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8374,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 12, 0, 528774),
 'item_scraped_count': 9,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 11, 4, 254664)}
2016-12-25 20:12:00 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:12:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:12:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:12:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:12:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:12:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:12:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:12:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:12:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:12:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:12:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:12:04 [scrapy] INFO: Spider opened
2016-12-25 20:12:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:12:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:12:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:12:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:12:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:12:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:12:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:12:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:12:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:12:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:12:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:12:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:12:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:12:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:12:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:12:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:12:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:12:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:12:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:12:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:12:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:12:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:12:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:12:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:12:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:12:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:12:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:12:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:12:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:12:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:12:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:12:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8377,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 12, 48, 556924),
 'item_scraped_count': 6,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 12, 4, 92218)}
2016-12-25 20:12:48 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:13:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:13:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:13:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:13:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:13:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:13:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:13:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:13:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:13:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:13:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:13:04 [scrapy] INFO: Spider opened
2016-12-25 20:13:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:13:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:13:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:13:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:13:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:13:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:13:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:13:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:13:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:13:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:13:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:13:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:13:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:13:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:13:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:13:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:13:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:13:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:13:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:13:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:13:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:13:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:13:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:13:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:13:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:13:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:13:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.238.16.112
2016-12-25 20:13:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:13:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:13:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:13:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:13:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:13:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:13:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:13:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:13:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:13:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:13:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:13:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:13:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:13:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:14:01 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:14:01 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:14:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:14:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:14:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:14:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:14:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:14:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:14:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:14:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:14:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:14:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:14:03 [scrapy] INFO: Spider opened
2016-12-25 20:14:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:14:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:14:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:14:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:14:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:14:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:14:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:14:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:14:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 20:14:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:14:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:14:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:14:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:14:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:14:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:14:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:14:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:14:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:14:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:14:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:14:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:14:17 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:14:17 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8322,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 14, 17, 672362),
 'item_scraped_count': 10,
 'log_count/DEBUG': 43,
 'log_count/ERROR': 2,
 'log_count/INFO': 52,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 13, 4, 299944)}
2016-12-25 20:14:17 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:14:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:14:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:14:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:14:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:14:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:14:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:14:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:14:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:14:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:14:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:14:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:14:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:14:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:14:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:14:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:14:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:14:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:14:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:14:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:14:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:14:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:14:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:14:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:14:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:14:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8324,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 14, 52, 287644),
 'item_scraped_count': 6,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 14, 3, 159644)}
2016-12-25 20:14:52 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:15:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:15:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:15:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:15:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:15:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:15:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:15:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:15:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:15:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:15:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:15:03 [scrapy] INFO: Spider opened
2016-12-25 20:15:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:15:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:15:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:15:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:15:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:15:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:15:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:15:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:15:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:15:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:15:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:15:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:15:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:15:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:15:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:15:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:15:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:15:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:15:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:15:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:15:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:15:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:15:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:15:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:15:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:15:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:15:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:15:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:15:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:15:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:15:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:15:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 20:15:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:15:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 20:15:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.242.2
2016-12-25 20:15:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:15:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:15:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:15:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8331,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 15, 56, 688677),
 'item_scraped_count': 4,
 'log_count/DEBUG': 20,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 15, 3, 296981)}
2016-12-25 20:15:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:16:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:16:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:16:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:16:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:16:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:16:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:16:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:16:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:16:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:16:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:16:03 [scrapy] INFO: Spider opened
2016-12-25 20:16:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:16:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:16:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:16:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:16:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:16:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:16:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:16:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:16:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:16:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:16:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:16:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:16:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:16:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:16:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:16:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:16:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:16:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:16:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:16:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:16:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:16:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:16:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 14.114.11.107
2016-12-25 20:16:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:16:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:16:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:16:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:16:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:16:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:16:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:16:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:16:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:16:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:16:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:16:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:16:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8443,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 16, 48, 660793),
 'item_scraped_count': 6,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 16, 3, 379932)}
2016-12-25 20:16:48 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:17:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:17:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:17:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:17:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:17:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:17:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:17:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:17:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:17:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:17:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:17:03 [scrapy] INFO: Spider opened
2016-12-25 20:17:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:17:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:17:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:17:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:17:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:17:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:17:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 20:17:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2923
2016-12-25 20:17:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:17:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:17:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:17:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:17:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:17:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:17:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:17:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:17:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:17:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:17:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:17:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:17:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:17:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:17:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:17:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:17:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:17:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:17:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 20:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:17:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:17:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:17:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:17:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:17:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:17:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:17:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:17:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:17:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:17:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:17:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:17:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:17:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:17:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:17:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:17:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:17:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:17:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:17:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:17:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:17:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:18:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:18:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:18:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:18:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:18:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:18:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:18:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:03 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:18:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8440,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 18, 3, 74984),
 'item_scraped_count': 6,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 17, 3, 347172)}
2016-12-25 20:18:03 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:18:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:18:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:18:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:18:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:18:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:18:03 [scrapy] INFO: Spider opened
2016-12-25 20:18:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:18:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:18:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:18:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:18:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:18:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:18:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:18:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 20:18:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:18:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:18:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:18:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:18:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:18:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:18:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:18:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:18:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:18:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:18:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:18:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:18:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:18:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:18:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:18:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:18:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:18:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:18:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:18:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:18:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:18:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:18:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:18:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:18:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:18:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:18:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:18:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:19:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:19:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:19:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:19:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:19:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:19:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:19:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8446,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 19, 2, 571563),
 'item_scraped_count': 10,
 'log_count/DEBUG': 40,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 18, 3, 298256)}
2016-12-25 20:19:02 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
200
connect failed!
2016-12-25 20:19:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:19:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:19:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:19:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:19:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:19:03 [scrapy] INFO: Spider opened
2016-12-25 20:19:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:19:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:19:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:19:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:19:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 49.68.236.115
2016-12-25 20:19:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:19:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:19:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:19:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:19:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:19:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:19:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:19:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:19:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:19:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:19:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:19:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:19:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:19:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:19:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:19:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:19:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:19:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:19:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:19:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:19:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:19:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:19:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:19:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:19:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:19:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:19:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:19:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:19:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:19:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:19:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:19:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:19:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:19:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:20:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:20:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8416,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 20, 1, 858207),
 'item_scraped_count': 9,
 'log_count/DEBUG': 39,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 19, 3, 383939)}
2016-12-25 20:20:01 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:20:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:20:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:20:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:20:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:20:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:20:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:20:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:20:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:20:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:20:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:20:03 [scrapy] INFO: Spider opened
2016-12-25 20:20:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:20:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:20:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:20:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:20:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:20:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:20:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:20:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:20:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 20:20:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:20:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:20:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:20:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:20:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:20:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:20:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:20:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:20:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:20:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:20:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:20:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:20:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:20:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:20:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:20:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:20:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:20:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:20:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:20:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:20:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:20:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:20:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:20:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:20:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:20:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:20:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:20:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:20:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:20:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:20:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:20:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:20:59 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:20:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:21:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:21:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8412,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 21, 1, 194601),
 'item_scraped_count': 3,
 'log_count/DEBUG': 18,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 20, 3, 426001)}
2016-12-25 20:21:01 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:21:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:21:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:21:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:21:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:21:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:21:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:21:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:21:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:21:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:21:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:21:03 [scrapy] INFO: Spider opened
2016-12-25 20:21:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:21:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:21:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:21:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:21:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:21:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:21:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 20:21:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:21:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:21:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 20:21:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:21:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:21:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:21:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:21:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:21:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:21:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:21:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:21:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:21:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:21:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:21:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:21:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:21:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:21:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:21:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:21:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.238.16.112
2016-12-25 20:21:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:21:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:21:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:21:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:21:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:21:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:21:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:21:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:21:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:21:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:21:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:21:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:21:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:21:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:21:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:21:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:21:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:21:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:21:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8420,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 21, 54, 156921),
 'item_scraped_count': 7,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 21, 3, 498383)}
2016-12-25 20:21:54 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
2016-12-25 20:22:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:22:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:22:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:22:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:22:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:22:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:22:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:22:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:22:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:22:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:22:03 [scrapy] INFO: Spider opened
2016-12-25 20:22:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:22:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:22:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:22:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:22:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:22:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:22:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:22:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:22:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:22:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:22:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:22:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:22:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:22:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:22:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:22:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:22:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:22:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:22:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:22:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:22:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:22:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:22:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:22:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:22:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:22:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:22:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:22:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:22:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:22:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:22:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:22:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:22:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:22:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:22:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:22:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:22:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:22:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:22:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:22:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:22:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:22:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8379,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 22, 59, 67403),
 'item_scraped_count': 7,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 22, 3, 281634)}
2016-12-25 20:22:59 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 20:23:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:23:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:23:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:23:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:23:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:23:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:23:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:23:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:23:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:23:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:23:03 [scrapy] INFO: Spider opened
2016-12-25 20:23:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:23:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:23:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:23:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:23:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:23:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:23:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:23:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:23:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:23:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:23:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:23:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:23:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 20:23:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:23:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.233.116.72
2016-12-25 20:23:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:23:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:23:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:23:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:23:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:23:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:23:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:23:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:23:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:23:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:23:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:23:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:23:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 20:23:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:23:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:23:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:23:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:23:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:23:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:23:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:23:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:23:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8378,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 23, 51, 243181),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 23, 3, 399731)}
2016-12-25 20:23:51 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
2016-12-25 20:24:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:24:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:24:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:24:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:24:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:24:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:24:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:24:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:24:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:24:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:24:03 [scrapy] INFO: Spider opened
2016-12-25 20:24:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:24:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:24:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.238.16.112
2016-12-25 20:24:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:24:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:24:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:24:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:24:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:24:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:24:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:24:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:24:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:24:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 20:24:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:24:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:24:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:24:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:24:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:24:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:24:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:24:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:24:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:24:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:24:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:24:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:24:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 20:24:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 14.114.11.107
2016-12-25 20:24:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:24:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:24:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:24:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:24:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:24:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:24:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:24:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:24:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:24:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:24:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:24:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:24:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8379,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 24, 49, 779631),
 'item_scraped_count': 7,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 24, 3, 474688)}
2016-12-25 20:24:49 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
2016-12-25 20:25:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:25:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:25:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:25:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:25:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:25:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:25:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:25:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:25:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:25:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:25:03 [scrapy] INFO: Spider opened
2016-12-25 20:25:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:25:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:25:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:25:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:25:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:25:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:25:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:25:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:25:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:25:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:25:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:25:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:25:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:25:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:25:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:25:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:25:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:25:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:25:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:25:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:25:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:25:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:25:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:25:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:25:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:25:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:25:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:25:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:25:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:25:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:25:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:25:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:25:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:25:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:25:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:25:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:25:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:25:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:25:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:25:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:25:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:25:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:25:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:25:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8509,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 25, 54, 985050),
 'item_scraped_count': 9,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 25, 3, 287998)}
2016-12-25 20:25:54 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:26:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:26:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:26:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:26:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:26:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:26:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:26:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:26:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:26:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:26:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:26:03 [scrapy] INFO: Spider opened
2016-12-25 20:26:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:26:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:26:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:26:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:26:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:26:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:26:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:26:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:26:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:26:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:26:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:26:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:26:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:26:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:26:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:26:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:26:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:26:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:26:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:26:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:26:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:26:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:26:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:26:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:26:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:26:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:26:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:26:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:26:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:26:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:26:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:26:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:26:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:26:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:26:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:26:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:26:47 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:26:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8512,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 26, 47, 731394),
 'item_scraped_count': 10,
 'log_count/DEBUG': 40,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 26, 3, 620863)}
2016-12-25 20:26:47 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:27:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:27:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:27:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:27:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:27:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:27:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:27:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:27:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:27:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:27:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:27:03 [scrapy] INFO: Spider opened
2016-12-25 20:27:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:27:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:27:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:27:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:27:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:27:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:27:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:27:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:27:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:27:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:27:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:27:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:27:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:27:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:27:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:27:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:27:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:27:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:27:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:27:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:27:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:27:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:27:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:27:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:27:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 20:27:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:27:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.233.116.72
2016-12-25 20:27:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:27:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:27:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:27:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:27:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 20:27:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:27:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:27:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 20:27:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:27:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:27:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:27:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:27:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:27:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:27:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:27:57 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:27:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:27:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:28:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8508,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 28, 1, 738478),
 'item_scraped_count': 12,
 'log_count/DEBUG': 44,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 27, 3, 419978)}
2016-12-25 20:28:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
2016-12-25 20:28:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:28:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:28:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:28:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:28:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:28:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:28:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:28:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:28:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:28:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:28:03 [scrapy] INFO: Spider opened
2016-12-25 20:28:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:28:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:28:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:28:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:28:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:28:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:28:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:28:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:28:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:28:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:28:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:28:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:28:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:28:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:28:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:28:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:28:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:28:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:28:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:28:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:28:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:28:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:28:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:28:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:28:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:28:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:28:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:28:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:28:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:28:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 20:28:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:28:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.233.116.72
2016-12-25 20:28:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:28:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:28:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:28:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:28:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:28:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:28:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:28:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:28:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:28:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:28:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8496,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 28, 54, 96730),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 28, 3, 888161)}
2016-12-25 20:28:54 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:29:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:29:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:29:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:29:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:29:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:29:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:29:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:29:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:29:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:29:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:29:03 [scrapy] INFO: Spider opened
2016-12-25 20:29:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:29:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:29:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:29:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:29:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:29:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:29:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:29:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:29:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:29:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:29:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:29:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:29:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:29:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:29:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:29:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:29:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:29:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:29:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:29:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:29:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:29:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:29:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:29:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:29:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:29:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:29:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:29:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:29:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:29:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:29:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:29:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:29:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.233.116.72
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:29:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:29:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:29:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:29:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:29:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:29:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:29:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:29:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8503,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 29, 54, 565263),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 29, 3, 569848)}
2016-12-25 20:29:54 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:30:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:30:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:30:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:30:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:30:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:30:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:30:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:30:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:30:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:30:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:30:03 [scrapy] INFO: Spider opened
2016-12-25 20:30:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:30:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:30:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:30:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:30:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:30:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:30:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:30:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:30:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:30:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:30:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:30:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:30:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:30:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:30:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:30:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:30:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:30:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:30:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:30:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:30:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:30:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:30:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:30:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:30:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:30:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:30:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:30:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:30:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:30:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:30:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:30:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:30:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:30:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:30:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 20:30:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:30:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8495,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 30, 49, 39965),
 'item_scraped_count': 7,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 30, 3, 419743)}
2016-12-25 20:30:49 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:31:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:31:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:31:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:31:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:31:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:31:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:31:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:31:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:31:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:31:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:31:03 [scrapy] INFO: Spider opened
2016-12-25 20:31:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:31:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:31:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:31:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:31:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:31:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:31:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:31:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:31:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:31:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:31:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:31:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:31:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:31:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:31:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:31:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:31:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:31:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:31:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:31:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:31:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:31:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:31:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:31:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:31:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:31:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:31:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:31:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:31:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:31:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:31:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:31:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:31:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:31:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:31:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:31:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 20:31:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:31:50 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:31:50 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8517,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 31, 50, 114240),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 31, 3, 561060)}
2016-12-25 20:31:50 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 20:32:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:32:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:32:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:32:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:32:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:32:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:32:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:32:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:32:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:32:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:32:03 [scrapy] INFO: Spider opened
2016-12-25 20:32:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:32:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:32:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:32:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:32:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:32:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:32:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:32:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:32:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:32:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:32:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:32:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:32:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:32:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:32:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:32:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:32:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:32:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:32:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:32:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:32:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:32:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:32:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:32:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:32:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:32:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:32:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:32:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:32:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:32:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:32:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:32:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:32:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:32:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:32:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:32:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:32:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:32:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8524,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 32, 53, 465631),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 32, 3, 607055)}
2016-12-25 20:32:53 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 20:33:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:33:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:33:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:33:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:33:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:33:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:33:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:33:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:33:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:33:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:33:03 [scrapy] INFO: Spider opened
2016-12-25 20:33:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:33:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:33:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:33:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:33:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:33:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:33:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:33:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:33:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:33:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:33:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:33:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:33:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:33:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:33:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:33:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:33:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:33:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:33:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:33:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:33:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:33:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:33:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:33:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:33:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:33:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:33:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:33:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:33:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:33:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:33:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:33:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:33:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:33:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:33:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:33:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:33:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:33:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:33:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:33:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 49.68.236.115
2016-12-25 20:33:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 20:33:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 20:33:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:33:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 20:33:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:33:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8520,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 33, 53, 711047),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 33, 3, 721855)}
2016-12-25 20:33:53 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 20:34:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:34:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:34:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:34:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:34:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:34:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:34:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:34:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:34:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:34:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:34:03 [scrapy] INFO: Spider opened
2016-12-25 20:34:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:34:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:34:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:34:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:34:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:34:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:34:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:34:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:34:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:34:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:34:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:34:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:34:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:34:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:34:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:34:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:34:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:34:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:34:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:34:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:34:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:34:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:34:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:34:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:34:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:34:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:34:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:34:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:34:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:34:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 223.244.50.186
2016-12-25 20:34:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:34:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:34:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.77.124
2016-12-25 20:34:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:34:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:34:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:34:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:34:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:34:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:34:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:34:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8495,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 34, 56, 841113),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 34, 3, 542931)}
2016-12-25 20:34:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:35:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:35:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:35:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:35:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:35:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:35:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:35:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:35:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:35:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:35:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:35:03 [scrapy] INFO: Spider opened
2016-12-25 20:35:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:35:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:35:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:35:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:35:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:35:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:35:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:35:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:35:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:35:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:35:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:16 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:35:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:35:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:35:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:35:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:35:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:35:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:35:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:35:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:35:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:35:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:35:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:35:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:35:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:35:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 20:35:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:35:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:35:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:35:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:35:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:35:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:35:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:35:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:35:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:35:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:35:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:35:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:35:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:35:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:35:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:35:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8501,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 35, 51, 959956),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 35, 3, 644669)}
2016-12-25 20:35:51 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:36:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:36:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:36:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:36:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:36:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:36:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:36:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:36:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:36:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:36:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:36:03 [scrapy] INFO: Spider opened
2016-12-25 20:36:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:36:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:36:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:36:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:36:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:36:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:36:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:36:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:36:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:36:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:36:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:36:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:36:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:36:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:36:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:36:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:36:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:36:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:36:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:36:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:36:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:36:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:36:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:36:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:36:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:36:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.77.124
2016-12-25 20:36:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.238.16.112
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 20:36:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.233.116.72
2016-12-25 20:36:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.42.10
2016-12-25 20:36:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:36:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.42.10
2016-12-25 20:36:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:36:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:36:45 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:36:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8499,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 36, 45, 420326),
 'item_scraped_count': 7,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 36, 3, 727468)}
2016-12-25 20:36:45 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:37:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:37:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:37:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:37:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:37:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:37:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:37:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:37:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:37:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:37:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:37:03 [scrapy] INFO: Spider opened
2016-12-25 20:37:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:37:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:37:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:37:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:37:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:37:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:37:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:37:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:37:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:37:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:37:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:37:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 20:37:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:37:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:37:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:37:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:37:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:37:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:37:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:37:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:37:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:37:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:37:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:37:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:37:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:37:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:37:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:37:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:37:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:37:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:37:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:37:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:37:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:37:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:37:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:38:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:38:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:38:00 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:38:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:38:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:38:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:38:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:38:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:38:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:38:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:38:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:38:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:38:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:38:03 [scrapy] INFO: Spider opened
2016-12-25 20:38:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:38:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:38:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:38:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:38:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:38:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:38:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:38:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 20:38:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:38:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:38:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:38:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:38:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:38:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:38:10 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:38:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8384,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 38, 10, 968763),
 'item_scraped_count': 9,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 51,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 37, 3, 668359)}
2016-12-25 20:38:10 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:38:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:38:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:38:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:38:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:38:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:38:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:38:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:38:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:38:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:38:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:38:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:38:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:38:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:38:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:38:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:38:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:38:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:38:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:38:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:38:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:38:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:38:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:38:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:38:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:38:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:38:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:38:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:38:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:38:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:38:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:38:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:38:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:38:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:38:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:38:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8387,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 38, 52, 288052),
 'item_scraped_count': 9,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 38, 3, 434565)}
2016-12-25 20:38:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:39:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:39:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:39:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:39:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:39:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:39:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:39:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:39:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:39:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:39:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:39:03 [scrapy] INFO: Spider opened
2016-12-25 20:39:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:39:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 20:39:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:39:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:39:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:39:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:39:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:39:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:39:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:39:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:39:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:39:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:39:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:39:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:39:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:39:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:39:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:39:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:39:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:39:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:39:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:39:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:39:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:39:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:39:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:39:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:39:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:39:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:39:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:39:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:39:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:39:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:39:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:39:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:39:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:39:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:39:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:39:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:39:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:39:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:40:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:40:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:40:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:40:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:40:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:40:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:40:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 20:40:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:40:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:40:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:40:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:40:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:40:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:40:03 [scrapy] INFO: Spider opened
2016-12-25 20:40:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:40:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:40:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:40:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:40:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:40:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:40:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:40:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:40:10 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 20:40:10 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:40:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8382,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 40, 10, 106090),
 'item_scraped_count': 9,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 39, 3, 578824)}
2016-12-25 20:40:10 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:40:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:40:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:40:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:40:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:40:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:40:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:40:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:40:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:40:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:40:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:40:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:40:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:40:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:40:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:40:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:40:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:40:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:40:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:40:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:40:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:40:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:40:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:40:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:40:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:40:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:40:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:40:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:40:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:40:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:40:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:40:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:40:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8377,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 40, 55, 295362),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 40, 3, 573665)}
2016-12-25 20:40:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:41:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:41:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:41:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:41:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:41:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:41:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:41:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:41:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:41:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:41:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:41:03 [scrapy] INFO: Spider opened
2016-12-25 20:41:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:41:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:41:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:41:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:41:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:41:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:41:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:41:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:41:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:41:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:41:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:41:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:41:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:41:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:41:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:41:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:41:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:41:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:41:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:41:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:41:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:41:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:41:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:41:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:41:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:41:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:41:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:41:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:41:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:41:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:41:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:41:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:41:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:41:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:41:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:41:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:41:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:41:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:41:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:42:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:42:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:42:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:42:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:42:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:42:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:42:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:42:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:42:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:42:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:42:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:42:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:42:03 [scrapy] INFO: Spider opened
2016-12-25 20:42:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:42:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 20:42:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:42:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:42:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:42:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 20:42:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:42:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8384,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 42, 4, 694393),
 'item_scraped_count': 7,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 41, 3, 733882)}
2016-12-25 20:42:04 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:42:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:42:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:42:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 20:42:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:42:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:42:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:42:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:42:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:42:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:42:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:42:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:42:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:42:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:42:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:42:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:42:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:42:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:42:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:42:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:42:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:42:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:42:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:42:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:42:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:42:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:42:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:42:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:42:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:42:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:42:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:42:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:42:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:42:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:42:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:42:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:42:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:42:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8383,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 42, 58, 388358),
 'item_scraped_count': 11,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 42, 3, 769307)}
2016-12-25 20:42:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:43:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:43:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:43:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:43:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:43:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:43:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:43:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:43:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:43:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:43:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:43:03 [scrapy] INFO: Spider opened
2016-12-25 20:43:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:43:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:43:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:43:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:43:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:43:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:43:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:43:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:43:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:43:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:43:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:43:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:43:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:43:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:43:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:43:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:43:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:43:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:43:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:43:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:43:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:43:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:43:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 171.217.23.210
2016-12-25 20:43:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:43:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:43:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:43:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:43:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:43:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:43:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:43:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:43:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:43:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:43:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:43:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:43:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:43:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:43:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:43:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:43:50 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:43:50 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8385,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 43, 50, 909457),
 'item_scraped_count': 10,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 43, 3, 879455)}
2016-12-25 20:43:50 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:44:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:44:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:44:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:44:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:44:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:44:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:44:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:44:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:44:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:44:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:44:03 [scrapy] INFO: Spider opened
2016-12-25 20:44:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:44:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:44:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:44:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:44:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:44:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:44:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:44:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:44:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:44:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:44:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:44:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:44:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:44:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:44:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:44:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:44:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:44:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:44:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:44:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:44:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:44:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:44:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:44:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:44:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:44:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:44:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:44:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:44:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:44:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:44:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:44:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:44:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:44:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.18.205.144
2016-12-25 20:44:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:44:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:44:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:44:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:44:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:44:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:44:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:44:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 223.244.50.186
2016-12-25 20:44:47 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:44:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8352,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 44, 47, 641104),
 'item_scraped_count': 14,
 'log_count/DEBUG': 49,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 44, 3, 829348)}
2016-12-25 20:44:47 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
2016-12-25 20:45:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:45:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:45:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:45:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:45:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:45:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:45:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:45:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:45:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:45:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:45:03 [scrapy] INFO: Spider opened
2016-12-25 20:45:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:45:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:45:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:45:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:45:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:45:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:45:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:45:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:45:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:45:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:45:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:45:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:45:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:45:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:45:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:45:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:45:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:45:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:45:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:45:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:45:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:45:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 20:45:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:45:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:45:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:45:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:45:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 20:45:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:45:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:45:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:45:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:45:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:45:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:45:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:45:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:45:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:45:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:45:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:45:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:45:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:45:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:45:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 20:45:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:45:57 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:45:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:45:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:46:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:46:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8352,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 46, 2, 281660),
 'item_scraped_count': 9,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 45, 3, 715349)}
2016-12-25 20:46:02 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:46:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:46:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:46:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:46:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:46:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:46:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:46:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:46:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:46:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:46:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:46:03 [scrapy] INFO: Spider opened
2016-12-25 20:46:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:46:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:46:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:46:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:46:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:46:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:46:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:46:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:46:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:46:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:46:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:46:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:46:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:46:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:46:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:46:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:46:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:46:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:46:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:46:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:46:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:46:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:46:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:46:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:46:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:46:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:46:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:46:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:46:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:46:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.217.23.210
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:46:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:46:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.133.204
2016-12-25 20:46:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.38.142.83
2016-12-25 20:46:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.109.216
2016-12-25 20:46:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:46:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 20:46:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 20:46:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 223.244.50.186
2016-12-25 20:46:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:46:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8349,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 46, 56, 84765),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 46, 3, 880358)}
2016-12-25 20:46:56 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:47:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:47:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:47:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:47:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:47:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:47:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:47:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:47:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:47:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:47:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:47:03 [scrapy] INFO: Spider opened
2016-12-25 20:47:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:47:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:47:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:47:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:47:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:47:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:47:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:47:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:47:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:47:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:47:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:47:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:47:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:47:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:47:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:47:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:47:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:47:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:47:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:47:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:47:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:47:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:47:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:47:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:47:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:47:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:47:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:47:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:47:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:47:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:47:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:47:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:47:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:47:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:47:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:47:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:47:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:47:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:47:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:47:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:47:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:47:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:47:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:47:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:47:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:47:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:47:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:48:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.138
2016-12-25 20:48:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:48:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:48:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:48:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:48:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:48:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:48:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:48:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:48:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:48:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:48:03 [scrapy] INFO: Spider opened
2016-12-25 20:48:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:48:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:48:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:48:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:48:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:48:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:48:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:48:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:48:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:48:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:48:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:48:10 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 20:48:10 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:48:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8269,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 48, 10, 213649),
 'item_scraped_count': 5,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 47, 3, 837542)}
2016-12-25 20:48:10 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:48:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:48:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:48:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 20:48:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:48:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:48:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:48:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:48:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:48:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:48:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:48:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:48:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:48:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:48:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:48:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:48:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:48:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:48:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:48:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:48:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:48:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:48:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:48:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:48:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:48:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:48:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:48:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:48:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:48:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:49:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:49:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:49:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:49:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:49:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:49:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:49:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:49:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:49:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:49:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:49:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:49:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:49:03 [scrapy] INFO: Spider opened
2016-12-25 20:49:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:49:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:49:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:49:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:49:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:49:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 20:49:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:05 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 12 items (at 12 items/min)
2016-12-25 20:49:05 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:49:05 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8277,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 49, 5, 750865),
 'item_scraped_count': 12,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 48, 3, 791754)}
2016-12-25 20:49:05 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 20:49:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:49:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:49:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:49:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:49:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:49:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:49:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:49:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:49:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:49:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:49:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:49:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:49:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:49:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:49:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:49:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:49:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:49:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:49:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:49:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:49:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:49:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:49:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:49:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:49:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:49:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:49:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:49:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:49:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:49:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:49:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:49:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:49:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:49:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:49:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:49:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:49:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:49:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:49:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:49:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 20:49:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 20:49:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:49:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 20:50:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:50:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:50:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:50:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:50:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:50:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:50:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8274,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 50, 2, 996208),
 'item_scraped_count': 9,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 49, 3, 803892)}
2016-12-25 20:50:03 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 20:50:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:50:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:50:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:50:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:50:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:50:03 [scrapy] INFO: Spider opened
2016-12-25 20:50:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:50:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:50:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:50:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:50:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:50:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:50:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:50:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 20:50:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:50:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:50:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:50:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:50:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:50:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:50:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:50:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:50:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:50:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:50:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:50:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:50:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:50:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:50:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:50:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:50:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:50:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:50:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:50:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:50:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:50:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:50:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:50:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:50:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:50:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:50:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:50:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 20:50:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:50:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:50:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:50:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:50:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:50:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8341,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 50, 57, 715541),
 'item_scraped_count': 6,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 50, 3, 890883)}
2016-12-25 20:50:57 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:51:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:51:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:51:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:51:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:51:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:51:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:51:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:51:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:51:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:51:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:51:03 [scrapy] INFO: Spider opened
2016-12-25 20:51:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:51:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:51:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:51:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:51:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:51:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:51:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:51:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:51:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:51:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:51:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:51:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:51:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:51:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:51:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:51:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:51:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:51:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:51:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:51:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:51:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:51:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:51:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:51:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:51:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:51:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:51:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:51:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:51:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:51:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:51:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:51:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:51:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:51:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:51:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:51:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:51:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:51:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:51:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:51:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8341,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 51, 59, 942559),
 'item_scraped_count': 4,
 'log_count/DEBUG': 19,
 'log_count/ERROR': 2,
 'log_count/INFO': 39,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 51, 3, 896464)}
2016-12-25 20:51:59 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:52:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:52:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:52:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:52:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:52:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:52:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:52:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:52:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:52:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:52:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:52:03 [scrapy] INFO: Spider opened
2016-12-25 20:52:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:52:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 20:52:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:52:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:52:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:52:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:52:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:52:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:52:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:52:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:52:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:52:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:52:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:52:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:52:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:26 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:52:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:52:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:52:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:52:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:52:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:52:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:52:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:52:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:52:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:52:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:52:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:52:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:52:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:52:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:52:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:52:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.138
2016-12-25 20:52:44 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:52:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8340,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 52, 44, 448411),
 'item_scraped_count': 7,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 52, 3, 975374)}
2016-12-25 20:52:44 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 20:53:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:53:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:53:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:53:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:53:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:53:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:53:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:53:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:53:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:53:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:53:04 [scrapy] INFO: Spider opened
2016-12-25 20:53:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:53:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:53:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:53:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:53:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:53:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:53:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:53:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:53:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:53:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:53:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:53:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:53:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:53:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:53:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:53:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:53:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:53:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:53:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:53:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 39.67.92.185
2016-12-25 20:53:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:53:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 20:53:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:53:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:53:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:53:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:53:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:53:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:53:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:53:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:53:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:53:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:53:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:53:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:53:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:53:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:53:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:53:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:53:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:53:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:53:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:53:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8358,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 53, 55, 707648),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 53, 4, 62683)}
2016-12-25 20:53:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:54:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:54:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:54:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:54:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:54:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:54:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:54:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:54:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:54:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:54:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:54:03 [scrapy] INFO: Spider opened
2016-12-25 20:54:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:54:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 20:54:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:54:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:54:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:54:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:54:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:54:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:54:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:54:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:54:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:54:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:54:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:54:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:54:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:54:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:54:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:54:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 20:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 403 0
2016-12-25 20:54:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:54:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:54:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:54:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:54:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:54:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:54:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 20:54:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:54:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:54:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:54:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:54:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:54:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:54:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:54:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:54:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:54:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:54:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:54:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:54:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:54:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:54:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:54:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8356,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 54, 52, 789187),
 'item_scraped_count': 10,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 54, 3, 860999)}
2016-12-25 20:54:52 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
connect failed!
200
200
connect failed!
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:55:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:55:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:55:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:55:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:55:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:55:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:55:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:55:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:55:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:55:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:55:04 [scrapy] INFO: Spider opened
2016-12-25 20:55:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:55:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 20:55:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:55:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:55:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:55:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:55:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:55:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:55:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:55:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:55:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:55:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:55:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:55:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 20:55:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:55:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:55:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:55:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:55:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:55:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:55:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 20:55:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:55:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:55:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:55:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:55:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:55:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:55:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:55:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:55:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:55:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 20:55:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:55:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:55:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:55:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:55:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:55:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:55:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:55:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:55:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 20:55:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.155.124.71
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.237.219.89
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.90.61.40
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 182.90.61.40
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:55:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:55:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.84.188
2016-12-25 20:56:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:56:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8358,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 56, 1, 475404),
 'item_scraped_count': 11,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 55, 4, 504620)}
2016-12-25 20:56:01 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 20:56:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:56:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:56:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:56:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:56:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:56:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:56:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:56:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:56:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:56:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:56:04 [scrapy] INFO: Spider opened
2016-12-25 20:56:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:56:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 20:56:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:56:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:56:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:56:10 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 20:56:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:56:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:56:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:56:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:56:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:56:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:56:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:56:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:56:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:56:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:56:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:56:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:56:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:56:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:56:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:56:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 20:56:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 20:56:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:56:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:56:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 20:56:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:56:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:56:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:56:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:56:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:56:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:56:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:56:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:56:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:56:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:56:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:56:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:56:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:56:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:56:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:56:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:57:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:57:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:57:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:00 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:57:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:57:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:01 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:57:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8355,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 57, 1, 844076),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 56, 4, 282706)}
2016-12-25 20:57:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
2016-12-25 20:57:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:57:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:57:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:57:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:57:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:57:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:57:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:57:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:57:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:57:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:57:04 [scrapy] INFO: Spider opened
2016-12-25 20:57:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:57:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 20:57:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:57:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:57:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:57:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:57:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:57:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:57:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:57:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:57:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:57:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:57:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:57:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:57:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:57:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:57:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:57:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:57:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:57:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:57:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:57:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:57:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:57:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 39.67.92.185
2016-12-25 20:57:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 4056
2016-12-25 20:57:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:57:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:57:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:57:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:57:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:57:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:57:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:57:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:57:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:57:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:57:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:57:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:57:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:57:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:57:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:57:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:57:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:57:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:57:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:57:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 20:57:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:57:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8359,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 57, 57, 166116),
 'item_scraped_count': 9,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 57, 4, 311370)}
2016-12-25 20:57:57 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
2016-12-25 20:58:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:58:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:58:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:58:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:58:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:58:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:58:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:58:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:58:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:58:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:58:04 [scrapy] INFO: Spider opened
2016-12-25 20:58:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:58:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 20:58:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:58:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:58:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:58:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:58:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:58:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:58:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 20:58:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:58:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:58:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 20:58:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:58:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:58:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:58:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:58:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:58:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:58:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:58:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 20:58:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:58:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 20:58:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:58:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 20:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:58:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:58:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:58:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:58:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:58:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:58:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 20:58:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:58:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 20:58:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 20:58:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 20:58:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:58:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:58:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 20:58:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:58:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 20:58:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 9445
2016-12-25 20:58:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:58:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 20:58:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8360,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 12, 58, 53, 484905),
 'item_scraped_count': 13,
 'log_count/DEBUG': 44,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 58, 4, 440237)}
2016-12-25 20:58:53 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
200
2016-12-25 20:59:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 20:59:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 20:59:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 20:59:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 20:59:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 20:59:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 20:59:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 20:59:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 20:59:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 20:59:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 20:59:04 [scrapy] INFO: Spider opened
2016-12-25 20:59:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 20:59:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 20:59:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 20:59:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 20:59:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 20:59:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 20:59:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 20:59:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 20:59:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:59:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:59:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 20:59:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 20:59:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 20:59:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 20:59:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 20:59:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:59:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:59:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 20:59:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 20:59:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 20:59:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 20:59:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 20:59:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 20:59:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 20:59:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 20:59:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:59:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 20:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 20:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 20:59:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:59:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 20:59:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 20:59:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 20:59:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 20:59:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 20:59:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 20:59:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 20:59:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 20:59:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 20:59:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 20:59:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 20:59:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 20:59:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 20:59:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:00:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 21:00:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:00:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:00:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:00:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:00:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:00:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:00:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:00:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:00:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:00:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:00:04 [scrapy] INFO: Spider opened
2016-12-25 21:00:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:00:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6031
2016-12-25 21:00:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:00:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:00:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:00:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:00:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 4 items (at 4 items/min)
2016-12-25 21:00:06 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:00:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8381,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 0, 6, 390939),
 'item_scraped_count': 4,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 12, 59, 4, 697537)}
2016-12-25 21:00:06 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:00:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:00:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:00:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:00:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:00:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:00:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:00:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:00:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:00:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:00:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:00:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:00:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:00:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:00:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:00:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:00:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:00:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:00:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:00:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:00:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:00:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:00:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:00:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:00:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:00:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:00:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 21:00:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:00:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 21:00:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:00:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 21:00:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 21:00:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:00:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:00:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 21:00:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:00:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:00:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:00:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:00:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:00:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:00:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8376,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 0, 55, 676561),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 0, 4, 730336)}
2016-12-25 21:00:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
2016-12-25 21:01:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:01:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:01:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:01:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:01:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:01:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:01:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:01:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:01:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:01:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:01:04 [scrapy] INFO: Spider opened
2016-12-25 21:01:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:01:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 21:01:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:01:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:01:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:01:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:01:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:01:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:01:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:13 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:01:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:01:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:01:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:01:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:01:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:01:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:01:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:01:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:01:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:01:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:01:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:01:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:01:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:01:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:01:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:01:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:01:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:01:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:01:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:01:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:01:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:01:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:01:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:01:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:01:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:01:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:01:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:01:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 21:01:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:01:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 21:01:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 21:01:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:01:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:01:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:01:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:01:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 21:01:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:01:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:01:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8384,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 1, 55, 345690),
 'item_scraped_count': 8,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 1, 4, 486794)}
2016-12-25 21:01:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 21:02:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:02:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:02:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:02:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:02:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:02:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:02:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:02:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:02:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:02:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:02:04 [scrapy] INFO: Spider opened
2016-12-25 21:02:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:02:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:02:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:02:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:02:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:02:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:02:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:07 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:02:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:02:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:02:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:02:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:02:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:02:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:02:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:02:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:02:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:02:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:02:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:02:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:02:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:02:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:02:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:02:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 21:02:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:02:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:02:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:02:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:02:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:02:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:02:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:02:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:02:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 21:02:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:02:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:02:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:02:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:02:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:02:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:02:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:02:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:02:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:02:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 21:02:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:02:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 21:02:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 21:03:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:03:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8308,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 3, 0, 860485),
 'item_scraped_count': 8,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 2, 4, 766819)}
2016-12-25 21:03:00 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:03:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:03:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:03:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:03:04 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:03:04 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:03:05 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:03:05 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:03:05 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:03:05 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:03:05 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:03:05 [scrapy] INFO: Spider opened
2016-12-25 21:03:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:03:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:03:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:03:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:03:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:03:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:03:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:03:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:03:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:03:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:03:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:03:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:03:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:03:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:03:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:03:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:03:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:03:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:03:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:03:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:03:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:03:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:03:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:03:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:03:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:03:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:03:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:03:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:03:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:03:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:03:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:03:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:03:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 21:03:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:03:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:03:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:03:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:03:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:03:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:03:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:03:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:03:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:03:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:03:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:03:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 21:04:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:04:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 21:04:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:04:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:04:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:04:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:04:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:04:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 21:04:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:04:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:04:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:04:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:04:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:04:04 [scrapy] INFO: Spider opened
2016-12-25 21:04:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:04:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:04:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:04:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:04:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:04:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:04:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 21:04:06 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:04:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8307,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 4, 6, 955634),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 3, 5, 149750)}
2016-12-25 21:04:06 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:04:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:04:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:04:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:04:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:04:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:04:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:04:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:04:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:04:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:04:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:04:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:04:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:04:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:04:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:04:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:04:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:04:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:04:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:04:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:04:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:04:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:04:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:04:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:04:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:04:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:04:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:04:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.49.252
2016-12-25 21:04:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:04:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.140.66
2016-12-25 21:04:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.32.168
2016-12-25 21:04:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:04:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8306,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 4, 52, 809159),
 'item_scraped_count': 6,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 40,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 4, 4, 838328)}
2016-12-25 21:04:52 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:05:04 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:05:04 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:05:04 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:05:04 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:05:04 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:05:05 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:05:05 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:05:05 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:05:05 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:05:05 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:05:05 [scrapy] INFO: Spider opened
2016-12-25 21:05:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:05:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:05:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:05:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:05:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:05:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:05:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:05:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:05:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:05:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:05:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:05:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:05:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:05:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:05:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:05:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:05:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:05:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:05:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:05:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:05:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:05:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:05:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:05:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:05:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:05:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:05:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:05:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:05:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:05:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:05:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:05:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:05:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:05:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:05:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:05:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:05:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:05:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:05:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:05:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:05:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:06:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:06:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:06:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:06:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:06:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:06:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:06:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:06:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:06:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:06:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:06:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:06:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:06:04 [scrapy] INFO: Spider opened
2016-12-25 21:06:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:06:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 21:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:06:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:06:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 21:06:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:06:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 21:06:07 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:06:07 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8298,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 6, 7, 165398),
 'item_scraped_count': 5,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 5, 5, 633783)}
2016-12-25 21:06:07 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:06:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:06:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:06:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:06:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:06:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:06:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:06:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:06:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:06:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:06:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:06:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:06:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:06:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:06:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:06:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:06:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:06:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:06:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:06:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:06:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:06:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:06:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:06:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:06:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:06:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 21:06:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 17528
2016-12-25 21:06:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:06:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:06:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:06:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:06:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:06:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:06:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:06:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:06:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:06:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:07:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:07:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:07:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:07:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:07:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:07:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:07:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:07:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:07:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:07:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:07:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:07:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:07:04 [scrapy] INFO: Spider opened
2016-12-25 21:07:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:07:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:07:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:07:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:07:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:07:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:07:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:07:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:07:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:07:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:07:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:07:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:07:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:07:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:07:12 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 21:07:12 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:07:12 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8300,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 7, 12, 344256),
 'item_scraped_count': 7,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 6, 4, 671734)}
2016-12-25 21:07:12 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:07:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:07:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:07:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:07:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:07:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:07:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:07:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:07:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:07:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:07:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:07:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:07:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:07:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:07:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:07:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:07:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:07:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:07:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:07:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:07:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:07:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:07:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:07:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:07:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:07:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:07:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:07:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:07:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:07:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:07:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:07:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:07:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:07:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.66.206
2016-12-25 21:07:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:07:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:07:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8299,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 7, 59, 202567),
 'item_scraped_count': 7,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 7, 4, 816457)}
2016-12-25 21:07:59 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
200
connect failed!
connect failed!
403
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:08:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:08:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:08:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:08:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:08:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:08:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:08:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:08:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:08:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:08:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:08:04 [scrapy] INFO: Spider opened
2016-12-25 21:08:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:08:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:08:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:08:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:08:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:08:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 21:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:08:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:08:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 21:08:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:08:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:08:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:08:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:08:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:08:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:08:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:08:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:08:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:08:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:08:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:08:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:08:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:08:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:08:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:08:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:08:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:08:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:08:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:08:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 21:08:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:08:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:08:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:08:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:08:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:08:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:08:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:08:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:08:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:08:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:08:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:08:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:08:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:08:45 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:08:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8287,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 8, 45, 585783),
 'item_scraped_count': 6,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 8, 4, 971492)}
2016-12-25 21:08:45 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
500
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:09:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:09:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:09:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:09:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:09:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:09:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:09:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:09:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:09:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:09:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:09:04 [scrapy] INFO: Spider opened
2016-12-25 21:09:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:09:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:09:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:09:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:09:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:09:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:09:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:09:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:09:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:09:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:09:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:09:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:09:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:09:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:09:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:09:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:09:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:09:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:09:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:09:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 21:09:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:09:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:09:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:09:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:09:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:09:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:09:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:09:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:09:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:09:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:09:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:09:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:09:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:09:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:09:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:09:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:09:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:09:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:09:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:09:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 39.67.92.185
2016-12-25 21:09:40 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:09:40 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8286,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 9, 40, 467247),
 'item_scraped_count': 9,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 9, 4, 913805)}
2016-12-25 21:09:40 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 21:10:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:10:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:10:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:10:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:10:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:10:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:10:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:10:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:10:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:10:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:10:04 [scrapy] INFO: Spider opened
2016-12-25 21:10:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:10:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 21:10:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:10:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:10:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:10:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:10:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 21:10:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:10:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:10:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 21:10:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:10:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:10:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 21:10:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:10:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:10:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:10:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:10:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:10:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:10:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:10:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:10:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:10:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:10:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:10:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:10:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:10:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:10:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:10:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:10:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:10:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:10:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:10:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:10:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 21:10:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 17528
2016-12-25 21:10:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:10:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:10:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:10:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:10:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:10:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:10:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:10:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 21:10:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 21:10:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:10:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:10:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:10:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:10:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:10:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 39.67.92.185
2016-12-25 21:10:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:10:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8288,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 10, 58, 774507),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 10, 4, 660729)}
2016-12-25 21:10:58 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 21:11:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:11:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:11:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:11:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:11:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:11:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:11:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:11:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:11:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:11:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:11:04 [scrapy] INFO: Spider opened
2016-12-25 21:11:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:11:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:11:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:11:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:11:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:11:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:11:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:11:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:11:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:11:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:11:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:11:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:11:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:11:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:11:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.121.249.228
2016-12-25 21:11:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:11:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:11:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:11:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:11:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:11:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:11:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:11:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:11:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:11:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:11:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:11:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:11:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:11:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:11:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:11:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:11:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:11:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:11:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:11:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:11:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:11:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:11:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:11:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:11:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:11:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:11:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:11:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:11:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:11:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:11:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:11:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:11:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:11:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8344,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 11, 51, 889481),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 11, 4, 881149)}
2016-12-25 21:11:51 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
2016-12-25 21:12:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:12:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:12:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:12:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:12:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:12:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:12:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:12:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:12:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:12:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:12:04 [scrapy] INFO: Spider opened
2016-12-25 21:12:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:12:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 21:12:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:12:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:12:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:12:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:12:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:12:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 21:12:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:12:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:12:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:12:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:12:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.68.76.132
2016-12-25 21:12:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:12:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:12:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:12:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:12:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.122.168.201
2016-12-25 21:12:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:12:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:12:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:12:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:12:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:12:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:12:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:12:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:12:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:12:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:12:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:12:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:12:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:12:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:12:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:12:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:12:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:12:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:12:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:12:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:12:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:12:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:13:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:13:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:13:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:13:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:13:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:13:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:13:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:13:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:13:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:13:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:13:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:13:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:13:04 [scrapy] INFO: Spider opened
2016-12-25 21:13:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:13:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 21:13:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:13:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:13:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:13:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:13:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:13:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:13:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:13:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 21:13:07 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:13:07 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8343,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 13, 7, 258111),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 12, 4, 840046)}
2016-12-25 21:13:07 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:13:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:13:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:13:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:13:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 21:13:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:13:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:13:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:13:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:13:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:13:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:13:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:13:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:13:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:13:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:13:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:13:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:13:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:13:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:13:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:13:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:13:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:13:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:13:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:13:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:13:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:13:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:13:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:13:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:13:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:13:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:13:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:13:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:13:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 21:13:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:13:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 21:13:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.18.205.144
2016-12-25 21:13:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:13:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:13:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:13:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:13:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 21:13:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:13:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8343,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 13, 48, 713346),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 13, 4, 914203)}
2016-12-25 21:13:48 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
500
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:14:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:14:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:14:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:14:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:14:04 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:14:05 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:14:05 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:14:05 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:14:05 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:14:05 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:14:05 [scrapy] INFO: Spider opened
2016-12-25 21:14:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:14:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:14:20 [scrapy] DEBUG: Retrying <GET http://www.xicidaili.com/robots.txt> (failed 1 times): DNS lookup failed: address 'www.xicidaili.com' not found: [Errno -2] Name or service not known.
2016-12-25 21:14:20 [scrapy] DEBUG: Retrying <GET http://www.xicidaili.com/nn/1/> (failed 1 times): DNS lookup failed: address 'www.xicidaili.com' not found: [Errno -2] Name or service not known.
2016-12-25 21:14:20 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:14:20 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:14:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:14:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:14:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:14:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:14:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:14:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:14:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:14:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:14:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:14:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:14:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:14:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:14:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:14:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:14:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:14:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:14:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:14:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:14:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:14:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:14:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:14:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:14:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:14:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:14:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:14:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:14:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:14:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:14:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:14:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:14:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:14:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:14:57 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:14:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:15:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:15:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:15:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:15:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:15:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:15:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:15:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:15:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 2,
 'downloader/request_bytes': 1062,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 8394,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 15, 4, 230232),
 'item_scraped_count': 6,
 'log_count/DEBUG': 25,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2016, 12, 25, 13, 14, 5, 45947)}
2016-12-25 21:15:04 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 21:15:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:15:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:15:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:15:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:15:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:15:04 [scrapy] INFO: Spider opened
2016-12-25 21:15:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:15:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:15:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:15:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:15:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:15:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 21:15:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:15:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:15:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:15:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:15:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:15:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:15:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:15:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:15:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:15:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:15:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:15:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:15:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:15:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:15:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:15:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:15:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:15:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:15:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:15:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:15:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:15:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:15:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.165.42.80
2016-12-25 21:15:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:15:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:15:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:15:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:15:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:15:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:15:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:15:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:15:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:15:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:15:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:15:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:15:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:15:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 21:15:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:15:44 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:15:44 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8386,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 15, 44, 604237),
 'item_scraped_count': 9,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 15, 4, 929379)}
2016-12-25 21:15:44 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
200
connect failed!
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
500
connect failed!
2016-12-25 21:16:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:16:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:16:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:16:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:16:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:16:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:16:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:16:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:16:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:16:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:16:04 [scrapy] INFO: Spider opened
2016-12-25 21:16:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:16:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:16:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:16:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:16:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:16:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:16:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:16:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:16:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:16:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:16:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:16:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:16:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:16:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:16:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:16:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:16:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:16:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:16:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:16:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:16:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 21:16:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:16:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:16:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:16:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:16:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:16:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:16:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:16:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.169.193.162
2016-12-25 21:16:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 500 192
2016-12-25 21:16:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:16:51 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:16:51 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8391,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 16, 51, 312467),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 16, 4, 703785)}
2016-12-25 21:16:51 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
500
connect failed!
2016-12-25 21:17:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:17:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:17:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:17:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:17:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:17:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:17:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:17:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:17:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:17:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:17:04 [scrapy] INFO: Spider opened
2016-12-25 21:17:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:17:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:17:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:17:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:17:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:17:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:17:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:11 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:17:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:17:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:17:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 21:17:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:17:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:17:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:17:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:17:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:17:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:17:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:17:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:17:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:17:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:17:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:17:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:17:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:17:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:17:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:17:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:17:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:17:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:17:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:17:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:17:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:17:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:17:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:17:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:17:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:17:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 21:17:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:17:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:17:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:17:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:17:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:17:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8450,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 17, 57, 901699),
 'item_scraped_count': 13,
 'log_count/DEBUG': 44,
 'log_count/ERROR': 2,
 'log_count/INFO': 48,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 17, 4, 697782)}
2016-12-25 21:17:57 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
connect failed!
connect failed!
200
200
200
200
200
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
2016-12-25 21:18:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:18:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:18:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:18:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:18:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:18:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:18:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:18:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:18:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:18:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:18:04 [scrapy] INFO: Spider opened
2016-12-25 21:18:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:18:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 21:18:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:18:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:18:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:18:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 21:18:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:18:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:18:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:18:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:18:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:18:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:18:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:18:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:18:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:18:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:18:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:18:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:18:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:18:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:18:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:18:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:18:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:18:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:18:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:18:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:18:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:18:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 21:18:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:18:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:18:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:18:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:18:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:18:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:18:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:18:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:18:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:18:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.126.100
2016-12-25 21:18:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:18:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:18:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:18:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8446,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 18, 53, 871006),
 'item_scraped_count': 8,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 18, 4, 810837)}
2016-12-25 21:18:53 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
503
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:19:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:19:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:19:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:19:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:19:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:19:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:19:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:19:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:19:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:19:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:19:04 [scrapy] INFO: Spider opened
2016-12-25 21:19:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:19:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:19:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:19:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:19:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:19:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:19:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:19:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:19:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:19:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:19:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 21:19:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:19:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:19:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:19:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:19:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:19:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:19:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:19:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:19:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:19:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:19:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:19:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:19:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:19:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:19:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:19:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:19:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:19:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:19:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:19:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:19:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:19:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.121.249.228
2016-12-25 21:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.68.76.132
2016-12-25 21:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 21:19:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.201
2016-12-25 21:19:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:19:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:19:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:19:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 21:19:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.122.168.41
2016-12-25 21:19:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:19:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.9.119
2016-12-25 21:19:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:19:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8452,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 19, 57, 520027),
 'item_scraped_count': 7,
 'log_count/DEBUG': 32,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 19, 4, 591522)}
2016-12-25 21:19:57 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:20:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:20:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:20:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:20:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:20:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:20:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:20:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:20:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:20:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:20:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:20:04 [scrapy] INFO: Spider opened
2016-12-25 21:20:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:20:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:20:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:20:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:20:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 21:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.28
2016-12-25 21:20:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:20:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:20:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.2
2016-12-25 21:20:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:20:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 21:20:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:20:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.73.107
2016-12-25 21:20:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:20:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.245.141
2016-12-25 21:20:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:20:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:20:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:20:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:20:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:20:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:20:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:20:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:20:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:20:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:20:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:20:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:20:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:20:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:20:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:20:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:20:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:20:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:20:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:20:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:20:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:20:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:20:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:20:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 21:21:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:21:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8207,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 21, 1, 476945),
 'item_scraped_count': 11,
 'log_count/DEBUG': 43,
 'log_count/ERROR': 2,
 'log_count/INFO': 50,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 20, 4, 634597)}
2016-12-25 21:21:01 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:21:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:21:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:21:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:21:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:21:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:21:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:21:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:21:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:21:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:21:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:21:04 [scrapy] INFO: Spider opened
2016-12-25 21:21:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:21:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 21:21:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:21:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:21:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:21:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 21:21:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:21:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:21:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:21:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.2
2016-12-25 21:21:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:21:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 21:21:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:21:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:21:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.245.141
2016-12-25 21:21:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:21:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:21:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:21:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:21:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:21:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:21:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:21:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:21:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:21:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:21:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:21:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:21:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:21:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:21:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:21:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:21:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:21:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:21:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:21:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:21:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:21:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:21:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:22:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:22:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:22:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:22:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:22:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:22:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:22:04 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:22:04 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:22:05 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:22:05 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:22:05 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:22:05 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:22:05 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:22:05 [scrapy] INFO: Spider opened
2016-12-25 21:22:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:22:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6031
2016-12-25 21:22:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:22:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:22:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:22:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:22:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:22:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:22:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 21:22:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 21:22:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:22:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:22:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:22:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:22:13 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 11 items (at 11 items/min)
2016-12-25 21:22:13 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:22:13 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8214,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 22, 13, 725393),
 'item_scraped_count': 11,
 'log_count/DEBUG': 39,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 21, 4, 910564)}
2016-12-25 21:22:13 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:22:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:22:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.2
2016-12-25 21:22:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:22:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 21:22:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:22:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.73.107
2016-12-25 21:22:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:22:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:22:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:22:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:22:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:22:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 21:22:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:22:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:22:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:22:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:22:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:22:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:22:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:22:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:22:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:22:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:22:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:22:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:22:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:23:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:23:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:23:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:23:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:23:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:23:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:23:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:23:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:23:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:23:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:23:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:23:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:23:03 [scrapy] INFO: Spider opened
2016-12-25 21:23:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:23:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 21:23:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:23:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:23:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:23:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:23:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:23:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:23:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:23:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:23:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:23:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:23:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:23:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:23:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.17.43.228
2016-12-25 21:23:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:23:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:23:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 220.166.241.13
2016-12-25 21:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 220.166.241.13
2016-12-25 21:23:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:23:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:23:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 21:23:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:23:20 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:23:20 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8210,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 23, 20, 611790),
 'item_scraped_count': 10,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 52,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 22, 5, 199174)}
2016-12-25 21:23:20 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 21:23:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.73.107
2016-12-25 21:23:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 21:23:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:23:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:23:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:23:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:23:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:23:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:23:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:23:59 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:24:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:24:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:24:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:24:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:24:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:24:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:24:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:24:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:24:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:24:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:24:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:24:03 [scrapy] INFO: Spider opened
2016-12-25 21:24:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:24:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:24:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:24:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:24:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:24:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:24:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:24:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:24:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:24:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:24:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:24:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:24:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:24:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:24:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:24:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:24:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:24:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:24:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:24:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:24:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:24:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:24:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:24:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:24:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.165.42.80
2016-12-25 21:24:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:19 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:24:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8189,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 24, 19, 158496),
 'item_scraped_count': 7,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 23, 3, 989719)}
2016-12-25 21:24:19 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
403
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
2016-12-25 21:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:24:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:24:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:24:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:24:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:24:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:24:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:24:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:24:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 21:24:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:25:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:25:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:25:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:25:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:25:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:25:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:25:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:25:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:25:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:25:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:25:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:25:03 [scrapy] INFO: Spider opened
2016-12-25 21:25:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:25:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:25:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:25:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:25:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:25:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:25:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:25:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:25:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:25:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:25:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:25:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:25:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:25:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:25:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:25:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:25:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:25:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:25:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:25:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:15 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 8 items (at 8 items/min)
2016-12-25 21:25:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:25:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:25:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:25:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:25:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:25:20 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:25:20 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8187,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 25, 20, 215083),
 'item_scraped_count': 9,
 'log_count/DEBUG': 38,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 24, 3, 901028)}
2016-12-25 21:25:20 [scrapy] INFO: Spider closed (finished)
connect failed!
200
403
200
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:25:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:25:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:25:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:25:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:25:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:25:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:25:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:25:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:25:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:25:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:25:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:25:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:25:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:25:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:25:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:25:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:25:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:25:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:25:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:25:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:25:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:25:55 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:25:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:25:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:26:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:26:02 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:26:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:26:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:26:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:26:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:26:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:26:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:26:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:26:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:26:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:26:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:26:03 [scrapy] INFO: Spider opened
2016-12-25 21:26:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:26:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:26:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:26:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:26:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:26:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:26:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:26:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:26:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:26:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:26:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 9 items (at 9 items/min)
2016-12-25 21:26:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:26:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:26:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:26:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:26:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.165.42.80
2016-12-25 21:26:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:26:09 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:26:09 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8189,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 26, 9, 594011),
 'item_scraped_count': 10,
 'log_count/DEBUG': 41,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 25, 3, 561510)}
2016-12-25 21:26:09 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
200
connect failed!
2016-12-25 21:26:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:26:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:26:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:26:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:26:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:26:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:26:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:26:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:26:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:26:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:26:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:26:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:26:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:26:51 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:26:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:26:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 21:26:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:26:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:26:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:26:56 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:26:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:26:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:26:56 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:26:56 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8176,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 26, 56, 302897),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 26, 3, 911790)}
2016-12-25 21:26:56 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
2016-12-25 21:27:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:27:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:27:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:27:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:27:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:27:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:27:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:27:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:27:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:27:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:27:03 [scrapy] INFO: Spider opened
2016-12-25 21:27:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:27:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 21:27:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:27:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:27:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:27:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:27:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:27:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:27:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:27:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:27:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:27:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:27:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:27:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:27:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:27:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:27:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:27:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:27:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:27:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:27:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:27:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:27:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:27:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:27:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:27:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:27:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:27:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:27:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:27:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:27:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:27:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 21:27:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:27:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:27:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:27:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:27:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:27:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:27:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:27:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:27:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:27:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:54 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 21:27:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:27:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:27:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:27:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:27:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:27:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:27:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:27:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8177,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 27, 58, 147732),
 'item_scraped_count': 9,
 'log_count/DEBUG': 36,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 27, 3, 934991)}
2016-12-25 21:27:58 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
2016-12-25 21:28:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:28:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:28:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:28:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:28:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:28:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:28:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:28:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:28:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:28:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:28:04 [scrapy] INFO: Spider opened
2016-12-25 21:28:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:28:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:28:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:28:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:28:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:28:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:28:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 21:28:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:28:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:28:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:28:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:28:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:28:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:28:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:28:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:28:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:28:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:28:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:28:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:28:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:28:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:28:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:28:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:28:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:28:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:28:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.76
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 183.129.151.130
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 183.129.151.130
2016-12-25 21:28:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:28:53 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:28:53 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:28:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8180,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 28, 53, 380552),
 'item_scraped_count': 8,
 'log_count/DEBUG': 33,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 28, 4, 37283)}
2016-12-25 21:28:53 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
2016-12-25 21:29:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:29:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:29:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:29:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:29:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:29:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:29:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:29:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:29:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:29:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:29:03 [scrapy] INFO: Spider opened
2016-12-25 21:29:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:29:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 21:29:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:29:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:29:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.84.132.78
2016-12-25 21:29:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.30.250
2016-12-25 21:29:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 2381
2016-12-25 21:29:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:29:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:29:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:29:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 21:29:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 21:29:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 21:29:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:29:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.233
2016-12-25 21:29:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:29:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:29:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:29:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:29:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:29:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:29:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:29:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:29:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:29:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:29:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:29:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:29:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:29:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:29:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:29:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:29:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:29:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:29:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 21:29:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:29:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:29:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:29:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:29:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:29:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:29:47 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:29:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8219,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 29, 47, 233519),
 'item_scraped_count': 11,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 29, 3, 668406)}
2016-12-25 21:29:47 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 21:30:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:30:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:30:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:30:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:30:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:30:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:30:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:30:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:30:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:30:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:30:04 [scrapy] INFO: Spider opened
2016-12-25 21:30:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:30:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 21:30:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:30:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:30:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.84.132.78
2016-12-25 21:30:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.30.250
2016-12-25 21:30:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:30:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:30:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:30:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:30:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:30:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:30:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:30:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:30:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:30:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:30:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:30:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:30:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:30:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:30:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:30:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:30:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:30:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:30:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:30:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:30:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:30:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:30:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:30:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:30:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:30:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:30:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:30:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:30:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:30:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:30:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:30:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:30:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:30:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:30:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:31:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:31:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:31:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:31:00 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:31:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8217,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 31, 0, 761645),
 'item_scraped_count': 4,
 'log_count/DEBUG': 19,
 'log_count/ERROR': 2,
 'log_count/INFO': 40,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 30, 4, 8392)}
2016-12-25 21:31:00 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
403
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 21:31:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:31:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:31:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:31:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:31:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:31:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:31:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:31:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:31:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:31:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:31:04 [scrapy] INFO: Spider opened
2016-12-25 21:31:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:31:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:31:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:31:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:31:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.84.132.78
2016-12-25 21:31:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.30.250
2016-12-25 21:31:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:31:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:31:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 21:31:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:31:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 21:31:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 21:31:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:31:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:31:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:31:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:31:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 21:31:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.233
2016-12-25 21:31:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 21:31:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 21:31:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:31:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:31:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:31:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:31:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:31:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:31:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:31:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:31:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:31:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:31:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:31:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.69
2016-12-25 21:31:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 21:31:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:31:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.2
2016-12-25 21:31:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:31:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.240.177
2016-12-25 21:31:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:31:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:31:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 21:31:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:51 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 21:31:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 21:31:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:31:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:31:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:32:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:32:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8216,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 32, 0, 291207),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 31, 4, 10085)}
2016-12-25 21:32:00 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
403
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 21:54:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:54:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:54:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:54:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:54:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:54:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:54:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:54:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:54:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:54:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:54:03 [scrapy] INFO: Spider opened
2016-12-25 21:54:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:54:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 21:54:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:54:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:54:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1021
2016-12-25 21:54:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:54:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:54:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 21:54:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:54:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:54:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:54:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:54:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:54:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:54:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:54:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:54:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 21:54:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:54:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:54:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:54:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:54:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:54:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 21:54:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:54:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:54:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 21:54:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:54:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 21:54:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 21:54:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 21:54:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:54:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:54:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:54:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:54:48 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:54:48 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8151,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 54, 48, 289652),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 54, 3, 855794)}
2016-12-25 21:54:48 [scrapy] INFO: Spider closed (finished)
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 21:56:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:56:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:56:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:56:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:56:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:56:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:56:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:56:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:56:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:56:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:56:04 [scrapy] INFO: Spider opened
2016-12-25 21:56:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:56:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 21:56:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:56:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:56:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:56:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:56:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:56:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:56:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 21:56:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:56:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 21:56:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:56:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:56:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:56:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:56:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:56:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:56:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:56:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:56:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 21:56:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:56:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:56:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:56:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 21:56:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:56:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:56:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:56:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:56:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:56:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 21:56:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:56:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:56:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:56:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 21:56:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 21:56:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 21:56:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:56:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.76
2016-12-25 21:56:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.28
2016-12-25 21:56:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:56:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.73.107
2016-12-25 21:56:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:57:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:57:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8155,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 57, 0, 779590),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 56, 4, 48427)}
2016-12-25 21:57:00 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 21:58:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 21:58:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 21:58:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 21:58:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 21:58:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 21:58:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 21:58:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 21:58:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 21:58:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 21:58:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 21:58:04 [scrapy] INFO: Spider opened
2016-12-25 21:58:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 21:58:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 21:58:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 21:58:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 21:58:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 21:58:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 21:58:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:58:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:58:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 21:58:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 21:58:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:58:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 21:58:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 21:58:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 21:58:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 21:58:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 21:58:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 21:58:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 21:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 21:58:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:58:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 21:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 21:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 21:58:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 21:58:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 21:58:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:58:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 21:58:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 21:58:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 21:58:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 21:58:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:58:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 21:58:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 21:58:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 21:58:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 21:58:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 21:58:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 21:58:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 21:58:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 21:58:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:58:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 21:58:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 21:58:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:58:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 21:58:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 21:58:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 21:58:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 21:59:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 21:59:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:59:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 21:59:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:59:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:59:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 21:59:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 21:59:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 21:59:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 21:59:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 21:59:04 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 21:59:04 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 12 items (at 12 items/min)
2016-12-25 21:59:04 [scrapy] INFO: Closing spider (finished)
2016-12-25 21:59:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8210,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 13, 59, 4, 284061),
 'item_scraped_count': 12,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 13, 58, 4, 219724)}
2016-12-25 21:59:04 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
2016-12-25 22:00:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:00:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:00:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:00:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:00:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:00:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:00:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:00:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:00:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:00:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:00:03 [scrapy] INFO: Spider opened
2016-12-25 22:00:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:00:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 22:00:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:00:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:00:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:00:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:00:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:00:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:00:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:00:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:00:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:00:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:00:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:00:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:00:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:00:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:00:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:00:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:00:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:00:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:00:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:00:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:00:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:00:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:00:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:00:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:00:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:00:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:00:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:00:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:00:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:00:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:00:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:00:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:01:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:01:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:01:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:01:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:01:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:01:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:01:05 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 22:01:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:01:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 22:01:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:01:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 22:01:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:01:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:01:09 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:01:09 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8211,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 1, 9, 213830),
 'item_scraped_count': 8,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 0, 3, 917949)}
2016-12-25 22:01:09 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
2016-12-25 22:02:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:02:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:02:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:02:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:02:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:02:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:02:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:02:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:02:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:02:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:02:04 [scrapy] INFO: Spider opened
2016-12-25 22:02:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:02:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 22:02:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:02:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:02:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:02:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:02:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:11 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:02:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:02:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:02:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:02:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:02:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:02:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:02:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:02:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:02:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:02:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:02:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:02:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:02:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:02:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:02:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:02:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:02:22 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:02:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:02:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:02:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:02:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:02:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:02:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:02:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:02:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:02:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:02:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:02:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:02:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:02:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:02:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:02:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:02:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:02:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:02:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:03:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:03:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 106.43.100.122
2016-12-25 22:03:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:03:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 106.43.100.122
2016-12-25 22:03:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:03:00 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:03:00 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:03:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8210,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 3, 0, 458720),
 'item_scraped_count': 10,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 2, 4, 253732)}
2016-12-25 22:03:00 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 22:04:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:04:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:04:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:04:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:04:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:04:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:04:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:04:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:04:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:04:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:04:04 [scrapy] INFO: Spider opened
2016-12-25 22:04:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:04:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6028
2016-12-25 22:04:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:04:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:04:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:04:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:04:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:04:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 22:04:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 17528
2016-12-25 22:04:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:04:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:04:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:04:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:04:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:04:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:04:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:04:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:04:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:04:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:04:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:04:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:04:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:04:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:04:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:04:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:04:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 22:04:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:04:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:04:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:04:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:04:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:04:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:04:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:04:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:04:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:04:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:04:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:04:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:42 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:04:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:04:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:04:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:04:51 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 0
2016-12-25 22:04:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:04:52 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:04:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:04:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:04:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:04:58 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:04:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:04:59 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:04:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:04:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8211,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 4, 59, 314966),
 'item_scraped_count': 13,
 'log_count/DEBUG': 50,
 'log_count/ERROR': 2,
 'log_count/INFO': 49,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 4, 4, 56430)}
2016-12-25 22:04:59 [scrapy] INFO: Spider closed (finished)
403
200
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
2016-12-25 22:06:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:06:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:06:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:06:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:06:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:06:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:06:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:06:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:06:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:06:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:06:04 [scrapy] INFO: Spider opened
2016-12-25 22:06:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:06:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:06:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:06:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:06:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:06:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:06:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:06:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:06:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:06:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:06:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:06:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:06:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:06:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:15 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:06:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:06:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:06:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:06:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:06:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:06:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 22:06:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:06:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:06:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:06:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:06:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:06:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:06:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:06:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:06:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:06:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:06:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:06:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:06:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:06:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:06:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:06:52 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:06:52 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:06:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:06:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 0
2016-12-25 22:06:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:06:57 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:06:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:07:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:07:03 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:07:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8205,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 7, 3, 996988),
 'item_scraped_count': 11,
 'log_count/DEBUG': 42,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 6, 4, 115464)}
2016-12-25 22:07:04 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
2016-12-25 22:08:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:08:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:08:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:08:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:08:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:08:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:08:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:08:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:08:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:08:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:08:04 [scrapy] INFO: Spider opened
2016-12-25 22:08:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:08:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 22:08:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:08:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:08:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:08:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:08:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:08:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:08:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:08:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:08:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:08:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:08:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:08:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:08:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:08:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:08:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:08:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:08:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:08:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:08:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:08:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:08:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:08:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:08:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 22:08:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:08:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:08:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:08:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:08:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:08:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:08:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:08:47 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:08:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8206,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 8, 47, 180677),
 'item_scraped_count': 10,
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 8, 4, 359991)}
2016-12-25 22:08:47 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:10:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:10:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:10:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:10:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:10:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:10:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:10:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:10:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:10:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:10:03 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:10:03 [scrapy] INFO: Spider opened
2016-12-25 22:10:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:10:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 22:10:03 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:10:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:10:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:10:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:10:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:10:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:10:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:10:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:10:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:10:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:10:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:10:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:10:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:10:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:10:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:10:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:10:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 22:10:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:10:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:10:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.12.99.213
2016-12-25 22:10:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:10:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:10:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:10:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:10:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:10:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:10:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:10:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:10:48 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:10:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:10:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:10:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:10:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:10:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:10:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:10:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:10:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:10:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:10:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:11:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.16.99
2016-12-25 22:11:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.4.54
2016-12-25 22:11:06 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 22:11:06 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:11:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8205,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 11, 6, 598456),
 'item_scraped_count': 6,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 10, 3, 876828)}
2016-12-25 22:11:06 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:12:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:12:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:12:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:12:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:12:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:12:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:12:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:12:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:12:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:12:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:12:04 [scrapy] INFO: Spider opened
2016-12-25 22:12:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:12:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 22:12:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:12:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:12:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:12:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:12:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:12:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:12:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:12:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:12:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:12:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:12:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:12:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:12:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:12:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:12:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:12:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:12:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:12:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 22:12:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:12:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:12:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:12:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:12:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:12:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:12:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:12:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:12:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:12:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:12:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:12:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:12:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:12:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:12:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:12:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:12:50 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:12:50 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8246,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 12, 50, 468616),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 12, 4, 57230)}
2016-12-25 22:12:50 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:14:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:14:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:14:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:14:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:14:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:14:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:14:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:14:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:14:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:14:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:14:04 [scrapy] INFO: Spider opened
2016-12-25 22:14:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:14:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:14:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:14:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:14:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:14:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:14:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:14:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:14:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:14:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:14:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:14:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:14:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:14:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:14:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:14:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:14:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:14:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:14:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:14:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:14:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:14:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:14:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:14:21 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:21 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:14:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:14:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:14:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:14:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:14:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:14:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:14:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:14:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:14:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:14:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:14:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:14:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:14:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:14:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 182.132.214.230
2016-12-25 22:14:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:14:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:14:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:14:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:14:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:14:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:14:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.241.122
2016-12-25 22:14:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.241.122
2016-12-25 22:14:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:14:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:14:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 22:14:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:14:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 171.39.26.78
2016-12-25 22:14:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:14:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8249,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 14, 55, 377448),
 'item_scraped_count': 10,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 14, 4, 74480)}
2016-12-25 22:14:55 [scrapy] INFO: Spider closed (finished)
200
connect failed!
200
200
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:16:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:16:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:16:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:16:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:16:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:16:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:16:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:16:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:16:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:16:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:16:04 [scrapy] INFO: Spider opened
2016-12-25 22:16:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:16:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 22:16:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:16:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:16:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:16:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:16:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:16:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:16:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:16:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:16:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:16:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:20 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:16:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:16:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:16:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:16:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:16:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:16:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:16:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:16:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:16:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:16:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:16:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:16:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:16:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:16:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:16:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:16:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:16:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:16:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:16:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:16:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:16:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:16:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:16:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:16:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:16:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:16:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:16:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:16:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:16:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:16:57 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:16:57 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:16:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:16:58 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:16:58 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:16:58 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8259,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 16, 58, 161323),
 'item_scraped_count': 8,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 16, 4, 103209)}
2016-12-25 22:16:58 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
200
403
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 22:17:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:17:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:17:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:17:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:17:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:17:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:17:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:17:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:17:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:17:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:17:04 [scrapy] INFO: Spider opened
2016-12-25 22:17:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:17:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 22:17:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:17:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:17:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:17:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:17:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 22:17:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:17:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:17:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:17:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:17:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:17:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:17:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:17:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:17:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:17:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:17:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:17:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:24 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:17:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:17:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:17:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:17:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:17:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:17:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:17:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:17:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:17:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:17:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:17:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:17:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:17:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:17:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:17:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 115.28.226.68
2016-12-25 22:17:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:17:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:17:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:17:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:17:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:17:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:17:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:17:50 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:17:50 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8254,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 17, 50, 405197),
 'item_scraped_count': 11,
 'log_count/DEBUG': 39,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 17, 4, 107626)}
2016-12-25 22:17:50 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
2016-12-25 22:18:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:18:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:18:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:18:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:18:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:18:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:18:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:18:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:18:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:18:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:18:04 [scrapy] INFO: Spider opened
2016-12-25 22:18:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:18:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:18:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:18:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:18:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:18:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:18:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:18:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:18:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:18:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:18:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:18:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:18:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:18:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:18:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:18:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:18:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:18:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:18:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:18:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:18:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:18:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:18:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:18:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:18:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:18:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:18:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 22:18:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:18:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:18:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:18:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:18:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:18:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:18:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:18:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:18:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:18:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:18:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:18:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:18:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:19:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:19:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:19:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:01 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:01 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:19:01 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 19, 1, 724032),
 'item_scraped_count': 6,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 42,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 18, 4, 272771)}
2016-12-25 22:19:01 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 22:19:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:19:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:19:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:19:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:19:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:19:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:19:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:19:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:19:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:19:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:19:04 [scrapy] INFO: Spider opened
2016-12-25 22:19:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:19:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 22:19:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:19:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:19:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:19:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:19:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:19:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:19:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:19:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 22:19:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:19:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:19:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:19:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:19:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:19:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:19:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:19:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:19:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:19:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:19:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:19:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:19:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:19:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:19:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:22 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 153.35.4.130
2016-12-25 22:19:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:19:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:19:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 22:19:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:19:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:19:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:19:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:19:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:19:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:19:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:19:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 221.175.232.183
2016-12-25 22:19:47 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:19:47 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:19:47 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:19:47 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8258,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 19, 47, 291329),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 19, 4, 843300)}
2016-12-25 22:19:47 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
2016-12-25 22:20:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:20:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:20:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:20:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:20:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:20:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:20:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:20:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:20:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:20:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:20:04 [scrapy] INFO: Spider opened
2016-12-25 22:20:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:20:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6029
2016-12-25 22:20:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:20:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:20:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:20:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:20:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:20:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 22:20:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:20:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:20:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:20:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:20:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:20:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:20:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:20:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:20:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:24 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:20:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:20:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:20:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:20:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:20:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:20:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:20:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 218.23.121.74
2016-12-25 22:20:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:20:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:20:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:20:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:20:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:20:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:20:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:20:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:20:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:20:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:20:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:20:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:20:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.28.226.68
2016-12-25 22:20:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.12.99.213
2016-12-25 22:20:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 221.175.232.183
2016-12-25 22:20:57 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:20:57 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8257,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 20, 57, 923215),
 'item_scraped_count': 7,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 20, 4, 635664)}
2016-12-25 22:20:57 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:21:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:21:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:21:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:21:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:21:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:21:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:21:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:21:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:21:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:21:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:21:04 [scrapy] INFO: Spider opened
2016-12-25 22:21:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:21:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 22:21:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:21:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:21:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:21:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 22:21:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:21:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:21:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:21:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:21:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:21:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:21:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:21:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:21:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:21:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 22:21:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:21:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 22:21:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:21:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:21:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:21:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:21:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:21:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:21:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:21:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:21:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:21:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:21:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:21:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:21:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:21:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:21:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:21:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:21:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:21:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:21:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:21:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:21:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:21:45 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:21:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8216,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 21, 45, 772823),
 'item_scraped_count': 6,
 'log_count/DEBUG': 26,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 21, 4, 529849)}
2016-12-25 22:21:45 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
403
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:22:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:22:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:22:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:22:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:22:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:22:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:22:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:22:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:22:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:22:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:22:04 [scrapy] INFO: Spider opened
2016-12-25 22:22:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:22:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:22:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:22:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:22:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:22:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:22:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:05 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:22:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:22:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:22:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:22:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:22:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:22:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:22:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:18 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:22:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:22:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:22:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:22:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:22:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:22:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:25 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:22:26 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:22:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:22:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:22:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:22:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:22:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:22:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:22:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:22:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 58.252.66.15
2016-12-25 22:22:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:22:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:22:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:22:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:22:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:22:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:22:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:22:55 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:22:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8213,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 22, 55, 896814),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 22, 4, 46148)}
2016-12-25 22:22:55 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:23:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:23:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:23:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:23:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:23:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:23:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:23:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:23:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:23:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:23:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:23:04 [scrapy] INFO: Spider opened
2016-12-25 22:23:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:23:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 22:23:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:23:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:23:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:23:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:23:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:23:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:23:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:23:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:23:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:23:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:23:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:23:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:23:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:23:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:25 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:23:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:23:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:23:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:23:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:23:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:23:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:23:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:23:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:23:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.148.108.126
2016-12-25 22:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 888
2016-12-25 22:23:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:23:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:23:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 153.35.4.130
2016-12-25 22:23:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:23:35 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:23:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:23:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:23:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:23:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:23:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:46 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:23:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:23:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:23:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:23:49 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:23:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:23:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:23:50 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:23:50 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:23:50 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:23:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 115.46.122.117
2016-12-25 22:23:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.166.119
2016-12-25 22:23:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.3.121
2016-12-25 22:23:59 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:23:59 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8216,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 23, 59, 203624),
 'item_scraped_count': 7,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 23, 4, 589134)}
2016-12-25 22:23:59 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:24:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:24:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:24:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:24:02 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:24:02 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:24:03 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:24:03 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:24:03 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:24:03 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:24:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:24:04 [scrapy] INFO: Spider opened
2016-12-25 22:24:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:24:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 22:24:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:24:06 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:24:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 0
2016-12-25 22:24:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:24:07 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:24:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:24:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:24:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:24:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:10 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:24:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:24:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:24:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:24:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:24:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:18 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:24:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:24:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:24:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:24:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:24:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:24:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:24:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:24:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:24:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:24:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 22:24:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:24:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:24:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:34 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:24:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 22:24:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:24:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:24:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:24:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:24:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.25.192.33
2016-12-25 22:24:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:24:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:24:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:24:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:24:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:24:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:24:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:24:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:24:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:24:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:24:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:24:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:24:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:24:52 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:24:52 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8278,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 24, 52, 89227),
 'item_scraped_count': 10,
 'log_count/DEBUG': 37,
 'log_count/ERROR': 2,
 'log_count/INFO': 44,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 24, 4, 9803)}
2016-12-25 22:24:52 [scrapy] INFO: Spider closed (finished)
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
200
200
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:25:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:25:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:25:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:25:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:25:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:25:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:25:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:25:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:25:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:25:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:25:04 [scrapy] INFO: Spider opened
2016-12-25 22:25:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:25:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 22:25:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:25:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:25:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:25:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:25:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:25:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:06 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:25:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:25:08 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:25:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:25:09 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:25:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:25:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:25:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:25:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:25:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:25:13 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:25:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 22:25:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:25:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:25:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:25:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:25:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:25:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:25:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:28 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 22:25:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:25:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:25:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:25:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 8455
2016-12-25 22:25:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:25:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:25:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:25:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:25:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:25:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:25:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:25:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 42.226.166.102
2016-12-25 22:25:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:25:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:25:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:25:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:25:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:25:49 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:25:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8276,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 25, 49, 888587),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 25, 4, 163087)}
2016-12-25 22:25:49 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:26:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:26:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:26:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:26:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:26:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:26:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:26:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:26:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:26:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:26:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:26:04 [scrapy] INFO: Spider opened
2016-12-25 22:26:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:26:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-12-25 22:26:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:26:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:26:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:26:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:26:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:08 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:26:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:26:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 22:26:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:26:14 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:26:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:26:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:26:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:26:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:26:19 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:26:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:26:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:26:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:26:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:26:28 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:26:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:26:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:26:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:26:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:26:34 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:26:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:26:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:26:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:26:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:26:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:26:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:26:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:26:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:26:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:26:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:26:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:26:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:26:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:26:54 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:26:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8276,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 26, 54, 462169),
 'item_scraped_count': 5,
 'log_count/DEBUG': 21,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 26, 4, 248689)}
2016-12-25 22:26:54 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:27:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:27:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:27:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:27:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:27:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:27:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:27:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:27:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:27:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:27:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:27:04 [scrapy] INFO: Spider opened
2016-12-25 22:27:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:27:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 22:27:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:27:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:27:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:27:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:27:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:27:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:27:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:27:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:27:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:13 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:27:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:17 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:27:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:27:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:27:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:27:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:27 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 23599
2016-12-25 22:27:27 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:27:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:27:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 22:27:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:27:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:27:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:27:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:27:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:27:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:27:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:27:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:27:53 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:53 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:27:54 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:27:54 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:27:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:27:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:27:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:27:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:27:58 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 205
2016-12-25 22:27:59 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3374
2016-12-25 22:27:59 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:27:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.25.192.33
2016-12-25 22:27:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:28:00 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:00 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.4.63.9
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:28:03 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.148.108.126
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 403 0
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 42.226.166.102
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 153.35.4.130
2016-12-25 22:28:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:28:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:28:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:03 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 153.35.4.130
2016-12-25 22:28:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:28:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:28:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:28:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:28:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:28:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:28:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:28:04 [scrapy] INFO: Spider opened
2016-12-25 22:28:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:28:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6026
2016-12-25 22:28:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:28:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:28:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:28:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:28:05 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:28:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 218.23.121.74
2016-12-25 22:28:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:28:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 58.252.66.15
2016-12-25 22:28:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:09 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 22:28:10 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2016-12-25 22:28:10 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:28:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8275,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 28, 10, 911678),
 'item_scraped_count': 6,
 'log_count/DEBUG': 29,
 'log_count/ERROR': 2,
 'log_count/INFO': 47,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 27, 4, 777263)}
2016-12-25 22:28:10 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
403
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:28:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:28:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:28:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:28:21 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:28:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:28:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:28:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:28:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:28:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:28:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:28:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 22:28:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:28:36 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:36 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:28:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:28:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:28:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:38 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:28:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:28:38 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:28:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:28:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:28:43 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:28:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:28:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:28:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:28:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:28:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:28:55 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:28:55 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 22:28:56 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:28:56 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:28:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:28:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:29:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 22:29:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:29:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:29:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:29:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:29:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:29:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:29:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:29:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:29:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:29:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:29:04 [scrapy] INFO: Spider opened
2016-12-25 22:29:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:29:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 22:29:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:29:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:29:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:29:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:29:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:29:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:29:08 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 7 items (at 7 items/min)
2016-12-25 22:29:08 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:29:08 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8257,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 29, 8, 373325),
 'item_scraped_count': 7,
 'log_count/DEBUG': 30,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 28, 4, 819028)}
2016-12-25 22:29:08 [scrapy] INFO: Spider closed (finished)
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
200
200
200
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:29:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:29:11 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:29:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:29:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:29:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:29:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 219.144.243.193
2016-12-25 22:29:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:29:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:29:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:29:25 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:29:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:29:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:29:28 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:29:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:29:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:29:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:29:31 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:31 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:29:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:29:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:29:32 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:32 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:29:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:32 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:29:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:29:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:29:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:29:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:29:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:29:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:29:38 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:29:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:29:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:29:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:29:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:29:51 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:29:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:29:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:29:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:30:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:30:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 113.15.179.63
2016-12-25 22:30:03 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:30:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8262,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 30, 3, 422815),
 'item_scraped_count': 6,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 43,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 29, 4, 285482)}
2016-12-25 22:30:03 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
200
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:30:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:30:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:30:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:30:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:30:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:30:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:30:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:30:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:30:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:30:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:30:04 [scrapy] INFO: Spider opened
2016-12-25 22:30:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:30:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6027
2016-12-25 22:30:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:30:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:30:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:30:08 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:30:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:30:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:12 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 60.21.209.114
2016-12-25 22:30:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:30:12 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:30:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:30:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:30:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:30:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:30:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:24 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:30:27 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:30:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:30:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:30:30 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:30:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:30:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:35 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:30:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:30:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:30:39 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:30:39 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:30:42 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:42 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:30:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 22:30:43 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:30:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:43 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:30:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:30:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:30:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:30:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:30:47 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:30:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:30:49 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 22:30:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:30:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:30:57 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:31:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:31:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:31:00 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:31:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:01 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.181.11.52
2016-12-25 22:31:01 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:31:01 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:01 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:31:02 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:02 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 119.53.126.98
2016-12-25 22:31:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:31:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:31:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:31:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:31:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:31:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:31:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:31:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:31:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:31:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:31:04 [scrapy] INFO: Spider opened
2016-12-25 22:31:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:31:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:31:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:31:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:31:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 22:31:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:31:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:31:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.61.20.147
2016-12-25 22:31:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:31:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 113.15.179.63
2016-12-25 22:31:11 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 22:31:11 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:31:11 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8260,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 31, 11, 958927),
 'item_scraped_count': 5,
 'log_count/DEBUG': 28,
 'log_count/ERROR': 2,
 'log_count/INFO': 46,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 30, 4, 932723)}
2016-12-25 22:31:11 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:31:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:31:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:31:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 22:31:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:31:17 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:31:18 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:31:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:31:22 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:31:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 22:31:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:31:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:31:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:31:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 125.118.243.183
2016-12-25 22:31:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:31:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:35 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 222.175.34.102
2016-12-25 22:31:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:31:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:31:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:31:37 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:31:39 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:39 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.176
2016-12-25 22:31:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 503 None
2016-12-25 22:31:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:31:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:31:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:31:41 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:31:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:31:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:44 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 118.178.180.213
2016-12-25 22:31:44 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:31:44 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:44 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:31:45 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:31:45 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:31:46 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:31:46 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:31:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:31:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:31:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:31:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:31:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:31:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:31:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:32:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:32:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:32:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:32:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:32:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:32:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:32:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:32:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:32:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:32:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:32:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:32:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:32:04 [scrapy] INFO: Spider opened
2016-12-25 22:32:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:32:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6030
2016-12-25 22:32:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:32:05 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:32:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 22:32:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:32:07 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 22:32:07 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:32:07 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8288,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 32, 7, 217936),
 'item_scraped_count': 5,
 'log_count/DEBUG': 24,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 31, 4, 668830)}
2016-12-25 22:32:07 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:32:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:32:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:32:15 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:32:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:15 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 121.204.165.160
2016-12-25 22:32:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:32:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:32:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:32:17 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:32:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:32:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:32:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 22:32:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:32:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:32:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:30 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:32:30 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:32:33 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:32:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:32:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:32:37 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:37 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:32:38 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:32:40 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:32:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:32:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:32:43 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:32:45 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:32:45 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:32:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:32:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:32:48 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:32:50 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:32:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:32:56 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:32:59 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:33:02 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:33:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:33:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:33:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:33:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:33:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:33:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:33:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:33:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:33:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:33:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:33:04 [scrapy] INFO: Spider opened
2016-12-25 22:33:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:33:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6025
2016-12-25 22:33:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.19.176.156
2016-12-25 22:33:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:33:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:33:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 22:33:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 503 None
2016-12-25 22:33:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:33:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1143
2016-12-25 22:33:06 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:33:07 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:33:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:07 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 36.249.195.226
2016-12-25 22:33:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:33:09 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:33:10 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:10 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2016-12-25 22:33:10 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:33:12 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:33:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:33:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:33:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:33:14 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 116.255.192.209
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:33:16 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:33:19 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:33:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8288,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 33, 19, 190570),
 'item_scraped_count': 5,
 'log_count/DEBUG': 23,
 'log_count/ERROR': 2,
 'log_count/INFO': 45,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 32, 4, 804014)}
2016-12-25 22:33:19 [scrapy] INFO: Spider closed (finished)
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
2016-12-25 22:33:19 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:33:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:19 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 59.51.41.202
2016-12-25 22:33:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:33:20 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:33:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:33:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:33:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:23 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 122.72.32.72
2016-12-25 22:33:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:33:23 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:23 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:33:26 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:33:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:26 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 114.231.66.26
2016-12-25 22:33:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 None
2016-12-25 22:33:29 [scrapy] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/1/>
None
2016-12-25 22:33:29 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:33:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:31 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 27.159.124.121
2016-12-25 22:33:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:33:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:33:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:33:40 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:33:40 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 101.29.213.119
2016-12-25 22:33:42 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:33:46 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:33:49 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:33:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.19.176.156
2016-12-25 22:33:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:33:55 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.181.11.52
2016-12-25 22:33:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 119.53.126.98
2016-12-25 22:33:58 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.61.20.147
2016-12-25 22:34:02 [scrapy] INFO: Closing spider (finished)
2016-12-25 22:34:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8292,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 34, 2, 472700),
 'item_scraped_count': 5,
 'log_count/DEBUG': 22,
 'log_count/ERROR': 2,
 'log_count/INFO': 41,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 33, 4, 288010)}
2016-12-25 22:34:02 [scrapy] INFO: Spider closed (finished)
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
200
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
2016-12-25 22:34:02 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapeIP)
2016-12-25 22:34:02 [scrapy] INFO: Optional features available: ssl, http11, boto
2016-12-25 22:34:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'scrapeIP.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['scrapeIP.spiders'], 'BOT_NAME': 'scrapeIP', 'AJAXCRAWL_ENABLED': True, 'COOKIES_ENABLED': False, 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0'}
2016-12-25 22:34:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2016-12-25 22:34:03 [boto] DEBUG: Retrieving credentials from metadata server.
2016-12-25 22:34:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2016-12-25 22:34:04 [boto] ERROR: Unable to read instance data, giving up
2016-12-25 22:34:04 [scrapy] INFO: Enabled downloader middlewares: RobotsTxtMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, AjaxCrawlMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, ChunkedTransferMiddleware, DownloaderStats
2016-12-25 22:34:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2016-12-25 22:34:04 [scrapy] INFO: Enabled item pipelines: ScrapeipPipeline
2016-12-25 22:34:04 [scrapy] INFO: Spider opened
2016-12-25 22:34:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:34:04 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-12-25 22:34:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/1/> (referer: None)
2016-12-25 22:34:04 [scrapy] DEBUG: Crawled (200) <GET http://www.xicidaili.com/robots.txt> (referer: None)
2016-12-25 22:34:04 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.10
2016-12-25 22:34:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:34:04 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 124.88.67.10
2016-12-25 22:34:04 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 3590
2016-12-25 22:34:34 [scrapy] ERROR: Error processing {'ip': u'124.88.67.10', '_id': ObjectId('585fd8dcd2a8b70711a7e830'), 'port': u'80'}
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/maoxianxin//scrapeIP/scrapeIP/pipelines.py", line 17, in process_item
    collection.insert_one(item)
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/collection.py", line 654, in insert_one
    with self._socket_for_writes() as sock_info:
  File "/usr/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 823, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/topology.py", line 214, in select_server
    address))
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/topology.py", line 189, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: 127.0.0.1:12345: [Errno 111] Connection refused
2016-12-25 22:34:34 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.4.63.9
2016-12-25 22:34:37 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 124.88.67.52
2016-12-25 22:34:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 36.249.195.226
2016-12-25 22:34:41 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.125.53.95
2016-12-25 22:34:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com.cn/ HTTP/1.1" 302 None
2016-12-25 22:34:41 [requests.packages.urllib3.connectionpool] INFO: Resetting dropped connection: 110.125.53.95
2016-12-25 22:34:41 [requests.packages.urllib3.connectionpool] DEBUG: "GET http://www.baidu.com/ HTTP/1.1" 200 1984
2016-12-25 22:35:06 [scrapy] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2016-12-25 22:35:11 [scrapy] ERROR: Error processing {'ip': u'110.125.53.95', '_id': ObjectId('585fd901d2a8b70711a7e832'), 'port': u'8118'}
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/maoxianxin//scrapeIP/scrapeIP/pipelines.py", line 17, in process_item
    collection.insert_one(item)
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/collection.py", line 654, in insert_one
    with self._socket_for_writes() as sock_info:
  File "/usr/lib/python2.7/contextlib.py", line 17, in __enter__
    return self.gen.next()
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 823, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/topology.py", line 214, in select_server
    address))
  File "/home/maoxianxin/.local/lib/python2.7/site-packages/pymongo/topology.py", line 189, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: 127.0.0.1:12345: [Errno 111] Connection refused
2016-12-25 22:35:11 [scrapy] INFO: Closing spider (shutdown)
2016-12-25 22:35:11 [scrapy] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.124.121
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 114.231.66.26
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 116.255.192.209
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.209.241.201
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.160
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.218.117.80
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.10.147
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 111.200.81.148
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 60.21.209.114
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 27.159.126.100
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 219.144.243.193
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.245.141
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.72.32.121
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 59.51.41.202
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 125.118.243.183
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 222.175.34.102
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 122.72.32.72
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.204.165.176
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 118.178.180.213
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 101.29.213.119
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.141.186
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 110.73.2.160
2016-12-25 22:35:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): 121.31.146.187
2016-12-25 22:35:11 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 531,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 8209,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2016, 12, 25, 14, 35, 11, 817534),
 'log_count/DEBUG': 8,
 'log_count/ERROR': 4,
 'log_count/INFO': 39,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2016, 12, 25, 14, 34, 4, 145752)}
2016-12-25 22:35:11 [scrapy] INFO: Spider closed (shutdown)
200
connect failed!
connect failed!
connect failed!
200
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
connect failed!
